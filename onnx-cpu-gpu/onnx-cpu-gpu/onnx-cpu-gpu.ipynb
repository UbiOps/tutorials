{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nearby-easter",
   "metadata": {},
   "source": [
    "# ONNX models on CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = '<INSERT API_TOKEN WITH PROJECT EDITOR RIGHTS>' # Make sure this is in the format \"Token token-code\"\n",
    "PROJECT_NAME= '<INSERT PROJECT NAME IN YOUR ACCOUNT>' # Fill in the corresponding UbiOps project name\n",
    "DEPLOYMENT_NAME = 'onnx-cpu-gpu'\n",
    "IMPORT_LINK = \"https://storage.googleapis.com/ubiops/deployment_exports/onnx-cpu-gpu-export.zip\"\n",
    "import shutil\n",
    "import ubiops\n",
    "import urllib.request \n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
    "configuration.api_key['Authorization'] = API_TOKEN\n",
    "\n",
    "client = ubiops.ApiClient(configuration)\n",
    "api = ubiops.CoreApi(client)\n",
    "api.service_status()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-nigeria",
   "metadata": {},
   "source": [
    "## Getting the models on UbiOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_confirmation = True # bool  (optional)\n",
    "\n",
    "# Create an import\n",
    "api_response = api.imports_create(PROJECT_NAME, import_link=IMPORT_LINK, skip_confirmation=skip_confirmation)\n",
    "print(api_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-shield",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unpack test images.\n",
    "\n",
    "urllib.request.urlretrieve(\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\", \"imagenette2-320.tgz\")\n",
    "shutil.unpack_archive(\"imagenette2-320.tgz\", \"./\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random selection of 100 images.\n",
    "\n",
    "pattern = \"imagenette2-320/val/*/*.JPEG\" # (or \"*.*\")\n",
    "filenames = random.choices(glob.glob(pattern),k=100)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual benchmarking\n",
    "\n",
    "ready = False\n",
    "while not ready:   # See if deployments are ready\n",
    "    time.sleep(5)\n",
    "    response = api.deployment_versions_list(project_name=PROJECT_NAME,\n",
    "        deployment_name=DEPLOYMENT_NAME)\n",
    "    statuses = [d.status == 'available' for d in response]\n",
    "    ready = all(statuses)\n",
    "    \n",
    "    print(\"Deployments are NOT ready\")\n",
    "\n",
    "print(\"Deployments are ready\")\n",
    "\n",
    "\n",
    "print(\"Uploading test images and making requests\")\n",
    "data = []\n",
    "\n",
    "# We are sending all images in one big batch request\n",
    "for image_file in tqdm(filenames):    \n",
    "    # First upload the image\n",
    "    file_uri = ubiops.utils.upload_file(client, PROJECT_NAME, image_file)\n",
    "    \n",
    "    # Make a request using the file uri as input.\n",
    "    data.append({'image': file_uri})\n",
    "    \n",
    "time.sleep(.05) # Let's not crash the api    \n",
    "api.batch_deployment_version_requests_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=\"gpu\",\n",
    "    data=data\n",
    ")\n",
    "\n",
    "api.batch_deployment_version_requests_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=\"cpu\",\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-antibody",
   "metadata": {},
   "source": [
    "Now go to the UbiOps logging page and take a look at the logs of both deployments. You should see a number printed in the logs. This is the average time that an inference takes. After that you can compare it to the following. This code will show the average request time. Note that this is different from each other. the average request time will also include overhead like downloading and uploading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version_id = api.deployment_versions_get(PROJECT_NAME,DEPLOYMENT_NAME, \"cpu\").id\n",
    "\n",
    "print(\"Average request time (s)\")\n",
    "\n",
    "api_response = api.metrics_get(\n",
    "    project_name=PROJECT_NAME,\n",
    "    object_type=\"deployment_version\",\n",
    "    object_id=version_id,\n",
    "    metric=\"compute\",\n",
    "    interval=\"day\",\n",
    "    start_date=str((datetime.today()- timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')),\n",
    "    end_date=str(datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ')),\n",
    ")\n",
    "print(f\"CPU: {api_response[-1].value}\")\n",
    "\n",
    "version_id = api.deployment_versions_get(PROJECT_NAME,DEPLOYMENT_NAME, \"gpu\").id\n",
    "\n",
    "\n",
    "api_response = api.metrics_get(\n",
    "    project_name=PROJECT_NAME,\n",
    "    object_type=\"deployment_version\",\n",
    "    object_id=version_id,\n",
    "    metric=\"compute\",\n",
    "    interval=\"day\",\n",
    "    start_date=str((datetime.today()- timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')),\n",
    "    end_date=str(datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ')),\n",
    ")\n",
    "print(f\"GPU: {api_response[-1].value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-twenty",
   "metadata": {},
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b956f356e97532e124a78bf3abf58bc4abb2e20db909e5dd1c0cfe7d3a45a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
