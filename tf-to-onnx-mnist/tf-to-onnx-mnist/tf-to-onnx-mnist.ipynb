{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BFz2g-DOUZzt"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://ubiops.com/wp-content/uploads/2020/12/Group-2.svg\" width=\"100\"/>\n",
        "</div>\n",
        "\n",
        "# Convert your MNIST model from Tensorflow to ONNX and run it on UbiOps twice as fast\n",
        "\n",
        "ONNX is an open format that is used to represent various Machine Learning models. It can also function as a model compression technique.  In this tutorial we will show you how to convert a Tensorflow based image classification algorithm to ONNX and \n",
        "run it on UbiOps using the ONNX runtime. We will show that this allows you to run an inferencing job twice as fast!\n",
        "\n",
        "First lets connect to UbiOps and load all of our dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02fnzn8UUaeT"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.10 tf2onnx==1.13.0 tqdm==4.64.1 ubiops>=3.12.0 protobuf>=3.19.4"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kRcy5owqWoVD"
      },
      "source": [
        "First connect to our API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScyAuiUWVFPk"
      },
      "outputs": [],
      "source": [
        "API_TOKEN = 'Token ' # Fill in your token here\n",
        "PROJECT_NAME = ''    # Fill in your project name here\n",
        "DEPLOYMENT_NAME = 'tf-vs-onnx-test'\n",
        "import ubiops \n",
        "import shutil\n",
        "import random, glob\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "\n",
        "configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
        "configuration.api_key['Authorization'] = API_TOKEN\n",
        "\n",
        "client = ubiops.ApiClient(configuration)\n",
        "api = ubiops.CoreApi(client)\n",
        "api.service_status()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AFa90uRXWvfy"
      },
      "source": [
        "## Converting the model\n",
        "\n",
        "We first download an h5 model from our public online bucket, then convert it as a `SavedModel`. Lastly, we convert it to an `onnx` model using the `tf2onnx` package.\n",
        "\n",
        "If everything worked correctly you should have the ONNX model at ```mnist_deployment_onnx_package/mnist.onnx```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ9178eBe3DT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#Get bucket from online repo\n",
        "bucket_name = \"ubiops\"\n",
        "file_path = \"demo-helper-files/cnn.zip\"\n",
        "\n",
        "# Create the URL for the file\n",
        "url = f\"https://storage.googleapis.com/{bucket_name}/{file_path}\"\n",
        "\n",
        "#Write zipfile to cnn folder\n",
        "urllib.request.urlretrieve(url, \"cnn\")\n",
        "\n",
        "#write modelfile to cnn_dir folder\n",
        "with zipfile.ZipFile(\"cnn\", 'r') as zip_ref:\n",
        "    zip_ref.extractall('cnn_dir')\n",
        "\n",
        "model = load_model(\"cnn_dir/cnn.h5\")\n",
        "\n",
        "#Save as a SavedModel to the mnist_model directory\n",
        "!mkdir mnist_model\n",
        "model.save(\"mnist_model\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MDr_aGktf2qF"
      },
      "source": [
        "## Preparing the comparison\n",
        "\n",
        "The next step is to create two deployments. One with the original Tensorflow based runtime and the second with the ONNX model runnning on the ONNX runtime.\n",
        "\n",
        "The following code will save the Tensorflow model, the requirements.txt's and the deployments.py's to the mnist_deployment_package directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R29Ouc-cf-AK"
      },
      "outputs": [],
      "source": [
        "!mkdir mnist_deployment_package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUuC9l1ekp3g"
      },
      "outputs": [],
      "source": [
        "#Copy the tensorflowmodel to the deployment package\n",
        "import shutil\n",
        "shutil.copy('cnn_dir/cnn.h5', 'mnist_deployment_package/cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr5Muas_f_wr"
      },
      "outputs": [],
      "source": [
        "%%writefile ./mnist_deployment_package/requirements.txt\n",
        "\n",
        "# This file contains package requirements for the deployment\n",
        "# installed via PIP. Installed before deployment initialization\n",
        "tensorflow==2.10\n",
        "imageio==2.26.0\n",
        "h5py==3.8.0\n",
        "numpy==1.24.1\n",
        "Pillow==9.4.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8Qo4TFyf5RT"
      },
      "outputs": [],
      "source": [
        "%%writefile ./mnist_deployment_package/deployment.py\n",
        "\"\"\"\n",
        "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
        "class and 'request' method.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from imageio import imread\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Deployment:\n",
        "\n",
        "    def __init__(self, base_directory, context):\n",
        "\n",
        "        print(\"Initialising deployment\")\n",
        "\n",
        "        weights = os.path.join(base_directory, \"cnn.h5\")\n",
        "        self.model = load_model(weights)\n",
        "\n",
        "    def request(self, data):\n",
        "\n",
        "        print(\"Processing request\")\n",
        "\n",
        "        x = imread(data['image'])\n",
        "        # convert to a 4D tensor to feed into our model\n",
        "        x = x.reshape(1, 28, 28, 1)\n",
        "        x = x.astype(np.float32) / 255\n",
        "\n",
        "        out = self.model.predict(x)\n",
        "\n",
        "        # here we set our output parameters in the form of a json\n",
        "        return {'prediction': int(np.argmax(out)), 'probability': float(np.max(out))}\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlmPpxmjlsU7"
      },
      "source": [
        "Now build a deployment package that hosts the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4aM1fFEqse5"
      },
      "outputs": [],
      "source": [
        "!mkdir mnist_deployment_onnx_package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU3HEzpiqt8S"
      },
      "outputs": [],
      "source": [
        "#Convert the model from SavedModel format to onnx, and store inside the ONNX deployment package\n",
        "!python3 -m tf2onnx.convert --saved-model mnist_model --opset 13 --output mnist_deployment_onnx_package/mnist.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDApd2j6lnCS"
      },
      "outputs": [],
      "source": [
        "%%writefile ./mnist_deployment_onnx_package/deployment.py\n",
        "\"\"\"\n",
        "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
        "class and 'request' method.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import onnxruntime as rt\n",
        "from imageio import imread\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Deployment:\n",
        "\n",
        "    def __init__(self, base_directory, context):\n",
        "        self.sess = rt.InferenceSession(\"mnist.onnx\")\n",
        "        self.input_name = self.sess.get_inputs()[0].name\n",
        "\n",
        "    def request(self, data):\n",
        "\n",
        "\n",
        "        x = imread(data['image'])\n",
        "        # convert to a 4D tensor to feed into our model\n",
        "        x = x.reshape(1, 28, 28, 1) \n",
        "        x = x.astype(np.float32) / 255\n",
        "\n",
        "        print(\"Prediction being made\")\n",
        "\n",
        "        prediction = self.sess.run(None, {self.input_name: x})[0]\n",
        "\n",
        "        return {'prediction': int(np.argmax(prediction)), 'probability': float(np.max(prediction))}\n",
        "\n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCitKKaol7Pk"
      },
      "outputs": [],
      "source": [
        "%%writefile ./mnist_deployment_onnx_package/requirements.txt\n",
        "\n",
        "# This file contains package requirements for the deployment\n",
        "# installed via PIP. Installed before deployment initialization\n",
        "\n",
        "onnx==1.12.0\n",
        "onnxruntime==1.12.0\n",
        "imageio==2.26.0\n",
        "numpy==1.24.1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fOC4_VilmHwH"
      },
      "source": [
        "Now that the deployment packages are created, you can upload them to UbiOps. We will make one deployment with two versions, one running Tensorflow while the other is running ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq9nbkpDl-6B"
      },
      "outputs": [],
      "source": [
        "mnist_template = ubiops.DeploymentCreate(\n",
        "    name=DEPLOYMENT_NAME,\n",
        "    description='A deployment to classify handwritten digits.',\n",
        "    input_type='structured',\n",
        "    output_type='structured',\n",
        "    input_fields=[\n",
        "        {'name': 'image', 'data_type': 'file'}\n",
        "    ],\n",
        "    output_fields=[\n",
        "        {'name': 'prediction', 'data_type': 'int'},\n",
        "        {'name': 'probability', 'data_type': 'double'}\n",
        "    ]\n",
        ")\n",
        "\n",
        "mnist_deployment = api.deployments_create(project_name=PROJECT_NAME, data=mnist_template)\n",
        "print(mnist_deployment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaCozzcKmJVh"
      },
      "outputs": [],
      "source": [
        "version_template = ubiops.DeploymentVersionCreate(\n",
        "    version=\"onnx\",\n",
        "    environment='python3-10',\n",
        "    instance_type='1024mb',\n",
        "    maximum_instances=1,\n",
        "    minimum_instances=0,\n",
        "    maximum_idle_time=1800, # = 30 minutes\n",
        "    request_retention_mode='full',  # input/output of requests will be stored\n",
        "    request_retention_time=3600  # requests will be stored for 1 hour\n",
        ")\n",
        "\n",
        "version = api.deployment_versions_create(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    data=version_template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T4S84gEmW9f"
      },
      "outputs": [],
      "source": [
        "# Zip the deployment package\n",
        "shutil.make_archive('mnist_deployment_onnx_package', 'zip', '.', 'mnist_deployment_onnx_package')\n",
        "\n",
        "\n",
        "upload_response = api.revisions_file_upload(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    version=\"onnx\",\n",
        "    file='mnist_deployment_onnx_package.zip'\n",
        ")\n",
        "print(upload_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FnSJ2B6mX9z"
      },
      "outputs": [],
      "source": [
        "version_template = ubiops.DeploymentVersionCreate(\n",
        "    version=\"tf\",\n",
        "    environment='python3-10',\n",
        "    instance_type='1024mb',\n",
        "    maximum_instances=1,\n",
        "    minimum_instances=0,\n",
        "    maximum_idle_time=1800, # = 30 minutes\n",
        "    request_retention_mode='full',  # input/output of requests will be stored\n",
        "    request_retention_time=3600  # requests will be stored for 1 hour\n",
        ")\n",
        "\n",
        "version = api.deployment_versions_create(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    data=version_template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC3xy3NrmY5J"
      },
      "outputs": [],
      "source": [
        "# Zip the deployment package\n",
        "shutil.make_archive('mnist_deployment_package', 'zip', '.', 'mnist_deployment_package')\n",
        "\n",
        "\n",
        "upload_response = api.revisions_file_upload(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    version=\"tf\",\n",
        "    file='mnist_deployment_package.zip'\n",
        ")\n",
        "print(upload_response)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1gu9RMyIme-L"
      },
      "source": [
        "## Benchmarking\n",
        "\n",
        "If everything went well there should now be a deployment in UbiOps with two versions. We can now compare the average request time by sending both versions a list of 100 images (one image per request.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRuUrO5dn9cg"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import zipfile\n",
        "#Get dummy data from our online bucket\n",
        "bucket_name = \"ubiops\"\n",
        "file_path = \"demo-helper-files/mnist_png.zip\"\n",
        "\n",
        "# Create the URL for the file\n",
        "url = f\"https://storage.googleapis.com/{bucket_name}/{file_path}\"\n",
        "\n",
        "urllib.request.urlretrieve(url, \"mnist_png.zip\")\n",
        "\n",
        "with zipfile.ZipFile(\"mnist_png.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6v4CPU2mc82"
      },
      "outputs": [],
      "source": [
        "pattern = \"mnist_png/testing/*/*.png\" # (or \"*.*\")\n",
        "filenames = random.choices(glob.glob(pattern),k=100)\n",
        "print(filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vHLbl2SoP2i"
      },
      "outputs": [],
      "source": [
        "ready = False\n",
        "while not ready:   \n",
        "    time.sleep(5)\n",
        "    response = api.deployment_versions_list(project_name=PROJECT_NAME,\n",
        "        deployment_name=DEPLOYMENT_NAME)\n",
        "    statuses = [d.status == 'available' for d in response]\n",
        "    ready = all(statuses)\n",
        "    \n",
        "    print(\"Deployments are NOT ready\")\n",
        "\n",
        "print(\"Deployments are ready\")\n",
        "\n",
        "print(\"Uploading test images and making requests\")\n",
        "\n",
        "for image_file in tqdm(filenames):    \n",
        "    # First upload the image\n",
        "    file_uri = ubiops.utils.upload_file(client, PROJECT_NAME, image_file)\n",
        "    \n",
        "    # Make a request using the file URI as input.\n",
        "    data = {'image': file_uri}\n",
        "    \n",
        "    time.sleep(.05) # Let's not crash the api    \n",
        "    api.deployment_version_requests_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        deployment_name=DEPLOYMENT_NAME,\n",
        "        version=\"onnx\",\n",
        "        data=data\n",
        "    )\n",
        "\n",
        "    api.deployment_version_requests_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        deployment_name=DEPLOYMENT_NAME,\n",
        "        version=\"tf\",\n",
        "        data=data\n",
        "    )\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7sWX3TLSobie"
      },
      "source": [
        "## Comparing the results\n",
        "\n",
        "Now that the request are finished we can look at the results. You can do that either by looking at the 'Metrics' tab of the UbiOps webappby running the following piece of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNvpThBmoSHJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "version_id = api.deployment_versions_get(PROJECT_NAME,DEPLOYMENT_NAME, \"tf\").id\n",
        "\n",
        "print(\"Average request time (s)\")\n",
        "\n",
        "api_response = api.metrics_get(\n",
        "    project_name=PROJECT_NAME,\n",
        "    object_type=\"deployment_version\",\n",
        "    object_id=version_id,\n",
        "    metric=\"compute\",\n",
        "    interval=\"day\",\n",
        "    start_date=str((datetime.today()- timedelta(days=1)).isoformat()),\n",
        "    end_date=str(datetime.today().isoformat()),\n",
        ")\n",
        "print(f\"Tensorflow: {api_response[-1].value}\")\n",
        "\n",
        "version_id = api.deployment_versions_get(PROJECT_NAME,DEPLOYMENT_NAME, \"onnx\").id\n",
        "\n",
        "\n",
        "api_response = api.metrics_get(\n",
        "    project_name=PROJECT_NAME,\n",
        "    object_type=\"deployment_version\",\n",
        "    object_id=version_id,\n",
        "    metric=\"compute\",\n",
        "    interval=\"day\",\n",
        "    start_date=str((datetime.today()- timedelta(days=1)).isoformat()),\n",
        "    end_date=str(datetime.today().isoformat())\n",
        ")\n",
        "print(f\"ONNX:       {api_response[-1].value}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JcqJpeyJoioV"
      },
      "source": [
        "# Cleaning up\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d3FZhlmodpX"
      },
      "outputs": [],
      "source": [
        "api.client_close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
