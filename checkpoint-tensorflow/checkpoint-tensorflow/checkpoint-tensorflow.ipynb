{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GjZHkvvzNlQW"
      },
      "source": [
        "# UbiOps Checkpoint TensorFlow"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2GBvYaNq8j"
      },
      "source": [
        "In this example, we train a simple model, to show how to save checkpoints in our file storage.  \n",
        "During the training run, we save model checkpoints to our file storage, making use of the TensorFlow callback class. At the end of our training run, we save plots of performance metrics."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Hb3I1JX3ds"
      },
      "source": [
        "First of all, let's install the required packages with pip in the current virtual environment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRWkwdY6X_S5"
      },
      "outputs": [],
      "source": [
        "!pip install \"ubiops >= 3.15\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iekRa2zYYHxr"
      },
      "source": [
        "Now it's time to set up all our project variables and to connect to our project using the UbiOps Client Library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--sqx6FjYXlQ"
      },
      "outputs": [],
      "source": [
        "import ubiops\n",
        "\n",
        "PROJECT_NAME = \" \" # Add the name of your project\n",
        "API_TOKEN = \"Token ...\" # Add an API Token with 'project editor' rights on your project\n",
        "\n",
        "ENVIRONMENT_NAME = \"checkpoint-tf-env\"\n",
        "EXPERIMENT_NAME = \"checkpoint-tf-experiment\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlkmR6TbYo7W"
      },
      "outputs": [],
      "source": [
        "configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
        "configuration.api_key['Authorization'] = API_TOKEN\n",
        "\n",
        "api_client = ubiops.ApiClient(configuration)\n",
        "core_instance = ubiops.CoreApi(api_client=api_client)\n",
        "training_instance = ubiops.Training(api_client=api_client)\n",
        "print(core_instance.service_status())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hLBGSow2O3fc"
      },
      "source": [
        "In this example, a very simple model is used to illustrate the checkpointing functionality.  \n",
        "We train a small Convolutional Neural network on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n",
        "The training job will be run inside the [UbiOps training section](https://ubiops.com/docs/training/), so the model code will be wrapped into the [UbiOps training function](https://ubiops.com/docs/training/#training-code-format)!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mphlxMW_ZjCE"
      },
      "source": [
        "Let's create 2 different directories, one directory to save the environment code and another to save our training code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmHn06GcM33K"
      },
      "outputs": [],
      "source": [
        "!mkdir training_environment\n",
        "!mkdir training_code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmw5p3CVaHRS"
      },
      "source": [
        "All our pip packages should be specified in a requirements.txt file for our environment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdVLyjjUZxe2"
      },
      "outputs": [],
      "source": [
        "%%writefile training_environment/requirements.txt\n",
        "ubiops >= 3.15\n",
        "tensorflow\n",
        "matplotlib\n",
        "numpy\n",
        "joblib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ryo8x3agIn"
      },
      "source": [
        "Now, we want to create a `train.py` file where our training code will be stored. The code will be explained after the code is given!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma-X1zGMegRZ"
      },
      "outputs": [],
      "source": [
        "%%writefile training_code/train.py\n",
        "import os\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import ubiops\n",
        "\n",
        "checkpoint_dir = \"checkpoint\"\n",
        "\n",
        "project_name = \"checkpoint-tensorflow\"\n",
        "\n",
        "\n",
        "class UbiOpsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, bucket_name, context):\n",
        "        super().__init__()\n",
        "        self.bucket_name = bucket_name\n",
        "        self.global_logs = {}\n",
        "        self.client_prod = ubiops.ApiClient(\n",
        "            ubiops.Configuration(api_key={'Authorization': os.environ[\"UBIOPS_API_TOKEN\"]})\n",
        "        )\n",
        "        self.context = context\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \"\"\"\n",
        "        This function is called at the end of each epoch. The function will upload the current model to UbiOps\n",
        "        for checkpointing.\n",
        "\n",
        "        :param epoch: the epoch number\n",
        "        :param logs: the logs of the epoch\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\nEpoch Finished: Logs are:\", logs)\n",
        "\n",
        "        model_dir = 'model_checkpoint'\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "\n",
        "        model_name = 'model'\n",
        "        joblib.dump(self.model, f\"{model_dir}/{model_name}.joblib\")\n",
        "\n",
        "        ubiops.utils.upload_file(\n",
        "            client=self.client_prod,\n",
        "            project_name=project_name,\n",
        "            file_path=f\"{model_dir}/{model_name}.joblib\",\n",
        "            bucket_name=self.bucket_name,\n",
        "            file_name=f\"deployment_requests/{self.context['id']}/checkpoints/model_epoch_{epoch}.joblib\"\n",
        "        )\n",
        "\n",
        "        # Update the global logs\n",
        "        self.global_logs.update({metric: self.global_logs.get(metric, []) + [value] for metric, value in logs.items()})\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        print(\"Training Finished\")\n",
        "        self.plot_logs()\n",
        "\n",
        "    def plot_logs(self):\n",
        "        \"\"\"\n",
        "        This function will plot the logs of the training and save them to the figure folder for later inspection.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if figure folder exists\n",
        "        if not os.path.exists(\"figure\"):\n",
        "            os.makedirs(\"figure\")\n",
        "\n",
        "        for key in self.global_logs:\n",
        "            file_name = f\"figure/{key}.png\"\n",
        "            plt.figure()\n",
        "            plt.title(key)\n",
        "\n",
        "            epochs = np.arange(1, len(self.global_logs[key]) + 1)\n",
        "            plt.plot(epochs, self.global_logs[key])\n",
        "            plt.ylabel(key)\n",
        "            plt.xlabel('epoch')\n",
        "            plt.xticks(np.arange(min(epochs), max(epochs) + 1, 1))\n",
        "            plt.savefig(file_name)\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            upload_location = f\"deployment_requests/{self.context['id']}/figures/{key}.png\"\n",
        "            print(f\"Uploading {file_name} to {upload_location}\")\n",
        "            ubiops.utils.upload_file(\n",
        "                client=self.client_prod,\n",
        "                project_name=project_name,\n",
        "                file_path=file_name,\n",
        "                bucket_name=self.bucket_name,\n",
        "                file_name=upload_location\n",
        "            )\n",
        "\n",
        "\n",
        "def train(training_data, parameters, context):\n",
        "    print(f\"Training data: {training_data}\")\n",
        "    print(f\"Parameters: {parameters}\")\n",
        "    print(f\"Context: {context}\")\n",
        "\n",
        "    # Define the model architecture\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Set callback\n",
        "    custom_callback = UbiOpsCallback(bucket_name=\"default\", context=context)\n",
        "\n",
        "    # Load data and train the model\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    x_train = x_train.reshape((60000, 784)).astype('float32') / 255.0\n",
        "    x_test = x_test.reshape((10000, 784)).astype('float32') / 255.0\n",
        "    y_train = tf.keras.utils.to_categorical(y_train)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "    epochs = parameters.get(\"epochs\", 3)\n",
        "    batch_size = parameters.get(\"batch_size\", 128)\n",
        "\n",
        "    result = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test),\n",
        "                       callbacks=[custom_callback])\n",
        "\n",
        "    # Get the loss and accuracy\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(model, \"model.joblib\")\n",
        "\n",
        "    return {\n",
        "        \"artifact\": \"model.joblib\",\n",
        "        \"metadata\": {},\n",
        "        \"metrics\": {\"accuracy\": accuracy},\n",
        "        \"additional_output_files\": []\n",
        "    }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "63CHOoAwenuU"
      },
      "source": [
        "As seen in the code above, the checkpointing is done by specifying a custom callback class `UbiOpsCallback` and setting that class as a callback in the `model.fit(...)` function.  \n",
        "After every epoch, the model in its current state will be saved in a bucket.  \n",
        "When the training is finished, the logs will be plotted in a graph and saved to a bucket to visually see how the model progressed after every epoch.\n",
        "Feel free to modify the code to your own liking, as this is just an example!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq0vjsgifpC5"
      },
      "source": [
        "Let's zip the environment directory!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pus_sW09fkQ1"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "training_environment_archive = shutil.make_archive('training_environment', 'zip', '.', 'training_environment')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kPpyOHJXcVAB"
      },
      "source": [
        "Let's enable the `training` functionality inside our project and create the environment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5dEtaHHc4FL"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    training_instance.initialize(project_name=PROJECT_NAME)\n",
        "except ubiops.exceptions.ApiException as e:\n",
        "    print(f\"The training feature may already have been initialized in your project: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t51c0-dGdabz"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    core_instance.environments_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        data=ubiops.EnvironmentCreate(\n",
        "            name=ENVIRONMENT_NAME,\n",
        "            display_name=ENVIRONMENT_NAME,\n",
        "            base_environment='python3-10',\n",
        "            description='Ubiops checkpointing environment with TensorFlow',\n",
        "        )\n",
        "    )\n",
        "except ubiops.exceptions.ApiException as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MGEMYZYhLxs"
      },
      "outputs": [],
      "source": [
        "core_instance.environment_revisions_file_upload(\n",
        "    project_name=PROJECT_NAME,\n",
        "    environment_name=ENVIRONMENT_NAME,\n",
        "    file=training_environment_archive\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xRYkS6DCgEXy"
      },
      "source": [
        "Let's wait for the environment to succeed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_f5R3F0c4FL"
      },
      "outputs": [],
      "source": [
        "ubiops.utils.wait_for_environment(core_instance.api_client, PROJECT_NAME, ENVIRONMENT_NAME, 600)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zr4DlGpyeOjY"
      },
      "source": [
        "Let's create an experiment now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NciVGPwzeRNA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    experiment = training_instance.experiments_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        data=ubiops.ExperimentCreate(\n",
        "            instance_type='2048mb',\n",
        "            description='TensorFlow checkpointing experiment with UbiOps',\n",
        "            name=EXPERIMENT_NAME,\n",
        "            environment=ENVIRONMENT_NAME,\n",
        "            default_bucket='default'\n",
        "        )\n",
        "    )\n",
        "except ubiops.exceptions.ApiException as e:\n",
        "    print(e)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KX2kFi-ej2DR"
      },
      "source": [
        "It's time to set our API Token as an environment variable. This way we can authenticate ourselves to upload files to a bucket, during our training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLkTVWd4kCrF"
      },
      "outputs": [],
      "source": [
        "api_token_env_var = ubiops.EnvironmentVariableCreate(\n",
        "    name=\"UBIOPS_API_TOKEN\",\n",
        "    value=API_TOKEN,\n",
        "    secret=True\n",
        ")\n",
        "\n",
        "core_instance.deployment_version_environment_variables_create(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=\"training-base-deployment\",\n",
        "    version=EXPERIMENT_NAME,\n",
        "    data=api_token_env_var\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_q9-LLOneV3B"
      },
      "source": [
        "Now it's time to upload the training code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VgbCNb5iTCv"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "try:\n",
        "    new_run = training_instance.experiment_runs_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        experiment_name=EXPERIMENT_NAME,\n",
        "        data=ubiops.ExperimentRunCreate(\n",
        "            name=f\"checkpoint-run-{datetime.now().isoformat()}\",\n",
        "            description='checkpointing run',\n",
        "            training_code=\"training_code/train.py\",\n",
        "            parameters=None \n",
        "        ),\n",
        "        timeout=14400\n",
        "    )\n",
        "except ubiops.exceptions.ApiException as e:\n",
        "    print(e)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nbpxonnmmv_"
      },
      "source": [
        "After our experiment is finished, we can take a look (in the web app) at the different generated files!\n",
        "If we take a look at the folder that is created with our deployment request (easily found by clicking on the output artifact location in our exeriment results!), we can see the following 3 folders:\n",
        "- **checkpoints** - folder containing all our checkpoint models\n",
        "- **figures** - folder containing all our log figures\n",
        "- **output** - folder containing the final model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dvs2nnlCoEex"
      },
      "source": [
        "The following figures are created:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qEgn_Ml5oc10"
      },
      "source": [
        "![val_loss.png](https://storage.googleapis.com/ubiops/data/Model%20Training/Tensorflow%20Checkpointing/val_loss.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f7AZgYGVoeGZ"
      },
      "source": [
        "![val_accuracy.png](https://storage.googleapis.com/ubiops/data/Model%20Training/Tensorflow%20Checkpointing/val_accuracy.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F_J0fNZhoheU"
      },
      "source": [
        "![loss.png](https://storage.googleapis.com/ubiops/data/Model%20Training/Tensorflow%20Checkpointing/loss.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pCBaxp6nolL2"
      },
      "source": [
        "![accuracy.png](https://storage.googleapis.com/ubiops/data/Model%20Training/Tensorflow%20Checkpointing/accuracy.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
