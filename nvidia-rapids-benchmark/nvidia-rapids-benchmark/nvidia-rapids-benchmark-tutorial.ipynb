{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SCnVK4QmDCF8"
      },
      "source": [
        "# Accelerate workflows with NVIDIA RAPIDS on UbiOps!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gos0V5WVD22e"
      },
      "source": [
        "[NVIDIA RAPIDS](https://developer.nvidia.com/rapids) is a suite of open-source software libraries and APIs developed by Nvidia that gives scientists and data analysts the ability to execute end-to-end data science and analytics pipelines completely on GPUs! This makes many different data analytics and machine learning workflows a lot faster.\n",
        "This tutorial will showcase how you can create a Linear Regression classifier on a synthetic dataset with different NVIDIA RAPIDS libraries, implemented on UbiOps!  \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vmC24zP3FZXC"
      },
      "source": [
        "The following steps are performed in this tutorial:\n",
        "\n",
        "1. Connect to the UbiOps API\n",
        "2. Create baseline model\n",
        "3. Accelerate model with NVIDIA RAPIDS\n",
        "4. Implement models into deployment\n",
        "5. Create UbiOps environment\n",
        "6. Create and upload deployment to UbiOps\n",
        "7. Run deployment\n",
        "8. Compare results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1lxx7LGpvZWe"
      },
      "source": [
        "Note that GPU access is needed in UbiOps to run this tutorial. UbiOps has support for GPU deployments, but this feature is not enabled for customers by default.\n",
        "Please [contact us](https://ubiops.com/contact-us/) for more information and to enable GPU access!\n",
        "It is recommended to connect to a GPU runtime (if available) for local testing purposes. If local testing is unwanted, a simple runtime will suffice as well for following this tutorial."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following results were achieved by using NVIDIA RAPIDS:  \n",
        "<style>\n",
        "    .image-container {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "    }\n",
        "    .image-container img {\n",
        "        max-width: 90%;\n",
        "        height: auto;\n",
        "        margin: 10px 10px;\n",
        "    }\n",
        "</style>\n",
        "\n",
        "<div class=\"image-container\">\n",
        "    <div>\n",
        "        <img src=\"https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/nvidia-rapids-benchmark/trainingtime.png\" />\n",
        "    </div>\n",
        "    <div>\n",
        "        <img src=\"https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/nvidia-rapids-benchmark/predtime.png\" />\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5hDjEyLb1gZr"
      },
      "source": [
        "## Connect to the UbiOps API"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nZkYhv7Y1lTR"
      },
      "source": [
        "Let's set up our workspace!  \n",
        "First things first, we are going to initialize our UbiOps Python Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJlSiiPFYaj"
      },
      "outputs": [],
      "source": [
        "!pip install \"ubiops >= 3.15, <4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIeJc6WH7IdI"
      },
      "outputs": [],
      "source": [
        "import ubiops\n",
        "\n",
        "\n",
        "API_TOKEN = \"Token ...\" # TODO: Add your UbiOps token here\n",
        "PROJECT_NAME = \"\" # TODO: Add your project name here\n",
        "\n",
        "ENVIRONMENT_NAME = \"nvidia-rapids-env\"\n",
        "\n",
        "DEPLOYMENT_NAME = \"nvidia-rapids-benchmark\"\n",
        "VERSION_NAME = \"v1\"\n",
        "\n",
        "DEPLOYMENT_DIR = \"deployment_package\"\n",
        "ENVIRONMENT_DIRECTORY_NAME = \"environment_package\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scSWk4F88HgW"
      },
      "outputs": [],
      "source": [
        "configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
        "configuration.api_key['Authorization'] = API_TOKEN\n",
        "\n",
        "api_client = ubiops.ApiClient(configuration)\n",
        "core_instance = ubiops.CoreApi(api_client=api_client)\n",
        "training_instance = ubiops.Training(api_client=api_client)\n",
        "print(core_instance.service_status())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8NluwbyJ8N8-"
      },
      "source": [
        "Now it's time to create directories to store our deployment/environment code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omDXN2PC8NnU"
      },
      "outputs": [],
      "source": [
        "!mkdir {DEPLOYMENT_DIR}\n",
        "!mkdir {ENVIRONMENT_DIRECTORY_NAME}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hojeXhdf8vOb"
      },
      "source": [
        "Now our workspace is all set up, let's start creating our baseline model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0yEFdhMV805j"
      },
      "source": [
        "## Create baseline model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KVnSIGCz9IfP"
      },
      "source": [
        "In order to showcase the performance improvements by utilizing NVIDIA RAPIDS, we want to have a baseline model to test against first. For this, we will create a simple `Random Forest` classifier.We are going to use [Scikit-Learn](https://scikit-learn.org/stable/) and [Pandas](https://pandas.pydata.org/) for this.  \n",
        "We are creating the following functions for the baseline model:\n",
        "- `generate_dataset`: Generate a random dataset for a certain amount of samples and features\n",
        "- `convert_to_pandas`: Convert our dataset to a `Pandas Dataframe` (useful for when we start creating an NVIDIA RAPIDS accelerated model)\n",
        "- `train_lr`: Train a Linear Regression model (with Scikit-Learn)\n",
        "- `make_predictions`: Make model predeictions\n",
        "- `calculate_mse`: Calculate the Mean Square Error (MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuKMcqcOAXVY"
      },
      "outputs": [],
      "source": [
        "%%writefile {DEPLOYMENT_DIR}/baseline_model.py\n",
        "\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class BaselineModel:\n",
        "    def __init__(self):\n",
        "        self.sklearn_lr = LinearRegression()\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_dataset(n_samples, n_features=20):\n",
        "        x, y = make_classification(n_samples=n_samples, n_features=n_features)\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "        return x_train, x_test, y_train, y_test\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_to_pandas(x_train, y_train, x_test):\n",
        "        pandas_x_train = pd.DataFrame(x_train)\n",
        "        pandas_y_train = pd.Series(y_train)\n",
        "        pandas_x_test = pd.DataFrame(x_test)\n",
        "        return pandas_x_train, pandas_y_train, pandas_x_test\n",
        "\n",
        "    def train_lr(self, pandas_x_train, pandas_y_train):\n",
        "        start_time = time.time()\n",
        "        self.sklearn_lr.fit(pandas_x_train, pandas_y_train)\n",
        "        return time.time() - start_time\n",
        "\n",
        "    def make_predictions(self, pandas_x_test):\n",
        "        start_time = time.time()\n",
        "        sklearn_predictions = self.sklearn_lr.predict(pandas_x_test)\n",
        "        return sklearn_predictions, time.time() - start_time\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_mse(y_test, sklearn_predictions):\n",
        "        return mean_squared_error(y_test, sklearn_predictions)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m2_S-d_zZaeW"
      },
      "source": [
        "## Accelerate model with NVIDIA RAPIDS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zCrMv7i4Zt-I"
      },
      "source": [
        "Now that we have our baseline model, we can accelerate this model by using the corresponding NVIDIA RAPIDS equivalent libraries/functions. The table below showcases the NVIDIA RAPIDS library equivalent to the \"standard\" library."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W0INRzV4bWVx"
      },
      "source": [
        "| Standard Libraries | NVIDIA RAPIDS Equivalent             |\n",
        "|--------------------|--------------------------------------|\n",
        "| Pandas             | cuDF                                 |\n",
        "| Scikit-learn       | cuML                                 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtPm5ATlbpA0"
      },
      "outputs": [],
      "source": [
        "%%writefile {DEPLOYMENT_DIR}/rapids_model.py\n",
        "\n",
        "import time\n",
        "import cudf\n",
        "from cuml.linear_model import LinearRegression\n",
        "from cuml.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "class RapidsModel:\n",
        "    def __init__(self):\n",
        "        self.cu_lr = LinearRegression()\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_to_cudf(pandas_x_train, pandas_y_train, pandas_x_test):\n",
        "        cudf_x_train = cudf.DataFrame.from_pandas(pandas_x_train)\n",
        "        cudf_y_train = cudf.Series(pandas_y_train)\n",
        "        cudf_x_test = cudf.DataFrame.from_pandas(pandas_x_test)\n",
        "        return cudf_x_train, cudf_y_train, cudf_x_test\n",
        "\n",
        "    def make_predictions(self, cudf_x_test):\n",
        "        start_time = time.time()\n",
        "        cu_predictions = self.cu_lr.predict(cudf_x_test)\n",
        "        return cu_predictions, time.time() - start_time\n",
        "\n",
        "    def train_lr(self, cudf_x_train, cudf_y_train):\n",
        "        start_time = time.time()\n",
        "        self.cu_lr.fit(cudf_x_train, cudf_y_train)\n",
        "        return time.time() - start_time\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_mse(y_test, cu_predictions):\n",
        "        return mean_squared_error(y_test, cu_predictions)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gLfSzzamf3C2"
      },
      "source": [
        "As you can see in the code block above, the core is exactly the same as in the baseline model! Some parameters are changed to give a better description, but all the function calls are entirely the same. The only difference is the library from which it is imported. In the baseline model, this is `sklearn`, in the accelerated model, it's `cudf` and `cuml`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jYKjCZ5yjgUH"
      },
      "source": [
        "## Implement models into deployment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1znNpCHXjj-f"
      },
      "source": [
        "Now that we've written our code for a baseline model and a NVIDIA RAPIDS accelerated model, we can integrate both into\n",
        "a UbiOps deployment. UbiOps deployment require fixed in- and outputs, as is outlined in the [documentation](https://ubiops.com/docs/deployments/deployment-package/deployment-structure/).  \n",
        "We will use the following input/output structure:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uiV02sSVmJF6"
      },
      "source": [
        "| Input/Output  |        Name        |      Type       | Description                           |\n",
        "|-------------- |:-----------------: | --------------: |-------------------------------------- |\n",
        "| Input         |     n_samples      |    Integer      | Number of samples in the dataset      |\n",
        "| Input         |     n_features     |    Integer      | Number of features per sample         |\n",
        "| Output        | scikit-mse         | Double Precision| Mean Squared Error using scikit-learn |\n",
        "| Output        | cuml-mse           | Double Precision| Mean Squared Error using cuML         |\n",
        "| Output        | scikit-train-time  | Double Precision| Training time using scikit-learn      |\n",
        "| Output        | cuml-train-time    | Double Precision| Training time using cuML              |\n",
        "| Output        | scikit-pred-time   | Double Precision| Prediction time using scikit-learn    |\n",
        "| Output        | cuml-pred-time     | Double Precision| Prediction time using cuML            |\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NT9UVdVvqIA0"
      },
      "source": [
        "Let's integrate the models into the UbiOps deployment structure, with the inputs/outputs as specified in the table above!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASCpFN-YqTrh"
      },
      "outputs": [],
      "source": [
        "%%writefile {DEPLOYMENT_DIR}/deployment.py\n",
        "\n",
        "import time\n",
        "\n",
        "from baseline_model import BaselineModel\n",
        "from rapids_model import RapidsModel\n",
        "\n",
        "\n",
        "class Deployment:\n",
        "    def __init__(self):\n",
        "        self.baseline_model = None\n",
        "        self.rapids_model = None\n",
        "\n",
        "    def request(self, data):\n",
        "        n_samples = data.get(\"n_samples\", 1000000)\n",
        "        n_features = data.get(\"n_features\", 20)\n",
        "\n",
        "        self.baseline_model = BaselineModel()\n",
        "        self.rapids_model = RapidsModel()\n",
        "\n",
        "        start_time = time.time()\n",
        "        x_train, x_test, y_train, y_test = self.baseline_model.generate_dataset(n_samples, n_features)\n",
        "        print(\"Dataset generation time: \", time.time() - start_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        pandas_x_train, pandas_y_train, pandas_x_test = self.baseline_model.convert_to_pandas(x_train, y_train, x_test)\n",
        "        print(\"Pandas conversion time: \", time.time() - start_time)\n",
        "\n",
        "        # Delete the dataframes to free up memory\n",
        "        del x_train, x_test, y_train\n",
        "\n",
        "        start_time = time.time()\n",
        "        cudf_x_train, cudf_y_train, cudf_x_test = self.rapids_model.convert_to_cudf(\n",
        "            pandas_x_train,\n",
        "            pandas_y_train,\n",
        "            pandas_x_test\n",
        "        )\n",
        "        print(\"CuDF conversion time: \", time.time() - start_time)\n",
        "\n",
        "        sklearn_train_time = self.baseline_model.train_lr(\n",
        "            pandas_x_train,\n",
        "            pandas_y_train,\n",
        "        )\n",
        "        cu_train_time = self.rapids_model.train_lr(cudf_x_train, cudf_y_train)\n",
        "\n",
        "        sklearn_predictions, sklearn_prediction_time = self.baseline_model.make_predictions(pandas_x_test)\n",
        "        cu_predictions, cu_prediction_time = self.rapids_model.make_predictions(cudf_x_test)\n",
        "\n",
        "        sklearn_mse = self.baseline_model.calculate_mse(y_test, sklearn_predictions)\n",
        "        cu_mse = self.rapids_model.calculate_mse(y_test, cu_predictions)\n",
        "\n",
        "        return {\n",
        "            \"scikit-mse\": sklearn_mse,\n",
        "            \"cuml-mse\": cu_mse.tolist(),\n",
        "            \"scikit-train-time\": sklearn_train_time,\n",
        "            \"cuml-train-time\": cu_train_time,\n",
        "            \"scikit-pred-time\": sklearn_prediction_time,\n",
        "            \"cuml-pred-time\": cu_prediction_time\n",
        "        }\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uFk7Yfjtqo_d"
      },
      "source": [
        "Now, our code is all set up! We can now continue to create our UbiOps environment and upload our model.  \n",
        "We can also test our code locally. We will do that in the next (sub)section, but is not necessary.  \n",
        "Do note that a NVIDIA GPU is needed and CUDA needs to be installed on the machine to test this deployment locally!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KsrsXKNzqlQd"
      },
      "source": [
        "### Test deployment locally"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zLeKp8m1qnCx"
      },
      "source": [
        "Before deploying our model, we can test its functionality locally as well. This will be done by running the deployment in the current Python environment.\n",
        "For this to succeed, the proper hardware and software is needed.\n",
        "To run the deployment locally, the following is needed:\n",
        "- NVIDIA GPU\n",
        "- CUDA Installed\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S2FBtij3wVng"
      },
      "source": [
        "We can test both by running the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nc43ydIwTvs"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OCS2JtYSwhQH"
      },
      "source": [
        "If we have the proper pre-requisites, the installed CUDA version and GPU information will be shown."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "meNCECSJw3g4"
      },
      "source": [
        "We furthermore need to install the proper pip packages by running the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3c7ZaBtw_qw"
      },
      "outputs": [],
      "source": [
        "!pip install --extra-index-url https://pypi.nvidia.com \\\n",
        "  wheel \\\n",
        "  setuptools \\\n",
        "  cudf-cu11 \\\n",
        "  cuml-cu11 \\\n",
        "  scikit-learn \\\n",
        "  pandas -q"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xIEa-YXxIsHW"
      },
      "source": [
        "Now that we have installed the proper packages, we can test the deployment locally!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBrTtHYAIwBm"
      },
      "outputs": [],
      "source": [
        "data_input = {\n",
        "    \"n_samples\": 10 ** 6,\n",
        "    \"n_features\": 50\n",
        "}\n",
        "\n",
        "ubiops.utils.run_local(DEPLOYMENT_DIR, data_input)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mXnmTsytKpf8"
      },
      "source": [
        "As we can see, our deployment works as expected.\n",
        "We can now upload our deployment to UbiOps!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-rmth0psK3zW"
      },
      "source": [
        "## Create UbiOps environment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cgpppVnjLMlm"
      },
      "source": [
        "Before uploading our deployment to UbiOps, we need to create an environment for the deployment to run in.\n",
        "This environment contains additional OS-level dependencies and pip packages. To specify the additional contents of an environment, the following 2 files need to be defined:\n",
        "- `requirements.txt`: This file specifies which pip packages need to be installed\n",
        "- `ubiops.yaml`: This file specifies the additional OS-level dependencies\n",
        "\n",
        "More information on UbiOps environments can be found in the [documentation](https://ubiops.com/docs/environments/)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3-W1o3fBObAA"
      },
      "source": [
        "Let's define our environment now!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wfQOz_VoOe8J"
      },
      "source": [
        "We first start of by creating the `requirements.txt` file with the pip packages we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vznv2g8rPtM0"
      },
      "outputs": [],
      "source": [
        "%%writefile {ENVIRONMENT_DIRECTORY_NAME}/requirements.txt\n",
        "\n",
        "--extra-index-url https://pypi.nvidia.com\n",
        "wheel\n",
        "setuptools\n",
        "cudf-cu11\n",
        "cuml-cu11\n",
        "scikit-learn\n",
        "pandas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ENck0LePQcX-"
      },
      "source": [
        "Now that we've specified the `requirements.txt` file, it's time to move on to the `ubiops.yaml` file.  \n",
        "In the environment, we need to have CUDA with some additional CUDA packages. UbiOps doesn't provide a base environment with the proper additional CUDA packages installed for this implementation. Therefore, we will install all the CUDA packages manually with the `ubiops.yaml` file!  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KWxSsjc-SsFF"
      },
      "source": [
        "The former can be achieved with the following `ubiops.yaml` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so3fm9WoSs4c"
      },
      "outputs": [],
      "source": [
        "%%writefile {ENVIRONMENT_DIRECTORY_NAME}/ubiops.yaml\n",
        "\n",
        "environment_variables:\n",
        "  - PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}\n",
        "  - LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\n",
        "apt:\n",
        "  keys:\n",
        "    urls:\n",
        "      - https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/3bf863cc.pub\n",
        "  sources:\n",
        "    items:\n",
        "      - deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64 /\n",
        "  packages:\n",
        "    - cuda-toolkit-11-7"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9XIx6XKAT-ku"
      },
      "source": [
        "We've just created all the files we need to make our own UbiOps environment.  \n",
        "We can now create an environment and then upload our files to it, do note that the environment might take a while to build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-qdaFQxUa6j"
      },
      "outputs": [],
      "source": [
        "# Create environment in UbiOps\n",
        "try:\n",
        "    core_instance.environments_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        data=ubiops.EnvironmentCreate(\n",
        "            name=ENVIRONMENT_NAME,\n",
        "            display_name=ENVIRONMENT_NAME,\n",
        "            base_environment=\"ubuntu22-04-python3-11\",\n",
        "            description=\"CUDA Toolkit 11.7 environment\",\n",
        "        )\n",
        "    )\n",
        "except ubiops.exceptions.ApiException as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLlsoBt1XuLY"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Upload files to environment\n",
        "try:\n",
        "    # Zip the directory with the training environment dependencies\n",
        "    environment_archive = shutil.make_archive(ENVIRONMENT_DIRECTORY_NAME, 'zip', ENVIRONMENT_DIRECTORY_NAME)\n",
        "\n",
        "    core_instance.environment_revisions_file_upload(\n",
        "        project_name=PROJECT_NAME,\n",
        "        environment_name=ENVIRONMENT_NAME,\n",
        "        file=environment_archive\n",
        "    )\n",
        "except ubiops.exceptions.ApiException as e:\n",
        "    print(e)\n",
        "\n",
        "# Wait for environment to be ready\n",
        "ubiops.utils.wait_for_environment(core_instance.api_client, PROJECT_NAME, ENVIRONMENT_NAME, 1800)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sWuF71zSYaYn"
      },
      "source": [
        "We have now created our environment on the UbiOps infrastructure.  \n",
        "Let's proceed to creating a deployment and uploading our deployment code."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ON3Xo5pHYuc8"
      },
      "source": [
        "## Create and upload deployment to UbiOps"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJpirXIAZYtv"
      },
      "source": [
        "Finally, we've reached the last step of the setup process: creating a deployment on Ubiops and uploading our deployment code to UbiOps."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tRBz-mLdZxUo"
      },
      "source": [
        "Let's begin by creating a new deployment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aOGzwyRZzht"
      },
      "outputs": [],
      "source": [
        "input_fields = [\n",
        "    {'name': 'n_samples', 'data_type': 'int'},\n",
        "    {'name': 'n_features', 'data_type': 'int'}\n",
        "]\n",
        "\n",
        "output_fields = [\n",
        "    {'name': 'scikit-mse', 'data_type': 'double'},\n",
        "    {'name': 'cuml-mse', 'data_type': 'double'},\n",
        "    {'name': 'scikit-train-time', 'data_type': 'double'},\n",
        "    {'name': 'cuml-train-time', 'data_type': 'double'},\n",
        "    {'name': 'scikit-pred-time', 'data_type': 'double'},\n",
        "    {'name': 'cuml-pred-time', 'data_type': 'double'}\n",
        "]\n",
        "\n",
        "\n",
        "deployment_template = ubiops.DeploymentCreate(\n",
        "    name=DEPLOYMENT_NAME,\n",
        "    description='Deployment to demonstrate NVIDIA RAPIDS model acceleration',\n",
        "    input_type='structured',\n",
        "    output_type='structured',\n",
        "    input_fields=input_fields,\n",
        "    output_fields=output_fields\n",
        ")\n",
        "\n",
        "deployment = core_instance.deployments_create(project_name=PROJECT_NAME, data=deployment_template)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pZDdkm0bcC_a"
      },
      "source": [
        "Now we add a deployment version to the newly created deployment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEzO6vxmeBby"
      },
      "outputs": [],
      "source": [
        "version_template = ubiops.DeploymentVersionCreate(\n",
        "    version=VERSION_NAME,\n",
        "    environment=ENVIRONMENT_NAME,\n",
        "    instance_type_group_name='16384 MB + 4 vCPU + NVIDIA Tesla T4',\n",
        "    maximum_instances=1,\n",
        "    minimum_instances=0,\n",
        "    maximum_idle_time=600, # = 10 minutes\n",
        "    request_retention_mode='full'\n",
        ")\n",
        "\n",
        "core_instance.deployment_versions_create(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    data=version_template\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlV-_yMGfYSR"
      },
      "source": [
        "At last, we upload our deployment code to the newly created deployment version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZES3io87fcN1"
      },
      "outputs": [],
      "source": [
        "deployment_archive = shutil.make_archive(DEPLOYMENT_DIR, 'zip', DEPLOYMENT_DIR)\n",
        "\n",
        "core_instance.revisions_file_upload(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    version=VERSION_NAME,\n",
        "    file=deployment_archive\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I2PoO8GUgNu_"
      },
      "source": [
        "Let's wait for our deployment to be done!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTb6qIrjgUOJ"
      },
      "outputs": [],
      "source": [
        "ubiops.utils.wait_for_deployment_version(core_instance.api_client, PROJECT_NAME, DEPLOYMENT_NAME, VERSION_NAME)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-FSEhNwshWsK"
      },
      "source": [
        "## Run deployment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NKEM7mX0hYGj"
      },
      "source": [
        "Now it's time to use our deployment.  \n",
        "Let's define a function to create a request and a function to plot results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHUgbYJ8hrO-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# function to create deployment requests\n",
        "def create_request(core_instance, features, samples):\n",
        "    data = {\n",
        "        \"n_features\": features,\n",
        "        \"n_samples\": 10**samples\n",
        "    }\n",
        "    request = core_instance.deployment_version_requests_create(\n",
        "        project_name=PROJECT_NAME,\n",
        "        deployment_name=DEPLOYMENT_NAME,\n",
        "        version=VERSION_NAME,\n",
        "        data=data\n",
        "    )\n",
        "    result_save = {\n",
        "        \"n_samples\": data[\"n_samples\"],\n",
        "        \"n_features\": data[\"n_features\"],\n",
        "        **request.result\n",
        "    }\n",
        "    print(request.result)\n",
        "    return result_save\n",
        "\n",
        "def plot_graph(results, time_key, title, feature_list):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Number of samples\")\n",
        "    plt.ylabel(\"Time (s)\")\n",
        "    plt.xscale(\"log\")\n",
        "\n",
        "    for i, features in enumerate(feature_list):\n",
        "        filtered_results = [result for result in results if result[\"n_features\"] == features]\n",
        "        n_samples = [result[\"n_samples\"] for result in filtered_results]\n",
        "        scikit_times = [result[f'scikit-{time_key}'] for result in filtered_results]\n",
        "        cuml_times = [result[f'cuml-{time_key}'] for result in filtered_results]\n",
        "        color = 'blue' if features == 5 else 'red'\n",
        "\n",
        "        plt.plot(n_samples, scikit_times, label=f\"Scikit-learn {features} features\", linestyle=\"dashed\", color=color)\n",
        "        plt.plot(n_samples, cuml_times, label=f\"CuML {features} features\", linestyle=\"solid\", color=color)\n",
        "    plt.legend()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CCkN4-ML5KPv"
      },
      "source": [
        "Let's call our function now and save the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1rUOGow2Op_"
      },
      "outputs": [],
      "source": [
        "features = [5, 50]\n",
        "range_samples = range(4,8)\n",
        "\n",
        "results = [create_request(core_instance, feature, n_samples) for n_samples in range_samples for feature in features]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh-NbYtg5RGf"
      },
      "source": [
        "We can proceed to plot the results now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoubSOGU3hgd"
      },
      "outputs": [],
      "source": [
        "plot_graph(results, \"train-time\", \"Training time\", features)\n",
        "plot_graph(results, \"pred-time\", \"Prediction time\", features)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h4gS-c4D5VWy"
      },
      "source": [
        "As we can see in our newly made plots, using NVIDIA RAPIDS libraries greatly speeds up our training time on bigger datasets. The prediction time doesn't benefit greatly from GPU parallelization in this use case (as parallelization potential doesn't outweigh the extra GPU overhead), but this could very well be much different for other applications."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2pFNWVnW6TmX"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CXZWnqdQ6W41"
      },
      "source": [
        "In this tutorial, we've made a Linear Regression model, improved the training time of this model greatly with NVIDIA RAPIDS and deployed a benchmark on UbiOps!  \n",
        "Don't hesitate to [contact us](https://ubiops.com/contact-us/) for any further information or to see what we can do for you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAQY_H617y5g"
      },
      "outputs": [],
      "source": [
        "# Close the UbiOps Python client\n",
        "api_client.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
