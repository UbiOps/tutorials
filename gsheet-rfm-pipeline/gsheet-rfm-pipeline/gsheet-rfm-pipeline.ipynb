{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Sheet RFM pipeline\n",
    "**Note**: This notebook runs on Python 3.8 and uses UbiOps CLient Library 3.15.0.\n",
    "\n",
    "In this notebook we will show you how to deploy a pipeline that:\n",
    "\n",
    "- Retrieves data from a google sheet\n",
    "- Performs a small RFM analysis on it \n",
    "- Writes the top customers back to the google sheet\n",
    "\n",
    "For this example we will use an opensourse customer data dataset from Kaggle that can be found [here](https://kaggle.com/mrmining/online-retail).\n",
    "\n",
    "The resulting pipeline in UbiOps will look like this:\n",
    "\n",
    "![pipeline](https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/pipeline.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your Google environment\n",
    "\n",
    "In order to run this notebook you will have to prepare a small set-up in your own google environment. Just follow along with the following steps:\n",
    "\n",
    "1. First, create a google sheet, name it `OnlineRetail` and paste the data from [the OnlineRetail dataset](https://kaggle.com/mrmining/online-retail) in the sheet.\n",
    "\n",
    "2. Head to [Google Developers Console](https://console.developers.google.com/) and create a new project (or select the one you have.)\n",
    "\n",
    "3. You will be redirected to the Project Dashboard, there click on \"Enable Apis and services\", search for \"Sheets API\".\n",
    "\n",
    "4. In the API screen click on \"ENABLE\" to enable this API\n",
    "\n",
    "![enable_api](https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/api_enable.png)\n",
    "\n",
    "5. Similarly enable the \"Drive API\".\n",
    "\n",
    "Now that we have the base set up, we still need to create a service account to use and give it access to the OnlineRetail data sheet.\n",
    "\n",
    "6. Go to \"Credentials\" tab and choose \"Create Credentials > Service Account\".\n",
    "\n",
    "7. Give the Service account a name and a description\n",
    "\n",
    "8. Set the service account permissions as \"Compute Engine Service Agent\", skip the third step and click create: \n",
    "\n",
    "<img src=\"https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/new_service_account.PNG\" width=\"700\">\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/permissions.png\" width=\"700\">\n",
    "\n",
    "9. Now navigate to the newly created service account and go to the \"Keys\" tab. Click \"Add Key > Create new Key\".\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/new_key.png\" width=\"700\">\n",
    "\n",
    "10. Set the type to JSON and click create. This will prompt a download of a json file which contains the necessary\n",
    "private key for account authorization. Store it in the same folder as this notebook.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/json_key.png\" width=\"700\">\n",
    "\n",
    "\n",
    "Pfew! Okay we are good to continue, everything should be correctly set up now. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing the OnlineRetail sheet with the service account\n",
    "\n",
    "Lastly, we need to make sure the service account actually has access to your sheet. To do this, head over to the Google Sheet you made before and clcik\n",
    "\"share\". Share the google sheet with the email address of the service account you created in the previous steps.\n",
    "The service account will need editor rights, as it will perform both read and write actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a connection with your UbiOps environment\n",
    "Add your API token and project name. You can also adapt the deployment name and deployment version name or leave the default values. Afterwards we initialize the client library, which establishes the connection with UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = '<YOUR TOKEN WITH PROJECT EDITOR RIGHTS>' # Should be of the form: Token ah23g4572\n",
    "PROJECT_NAME= '<YOUR PROJECT NAME>'\n",
    "\n",
    "# Import all necessary libraries\n",
    "import shutil\n",
    "import os\n",
    "import ubiops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can open the connection to UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ubiops.ApiClient(ubiops.Configuration(api_key={'Authorization': API_TOKEN}, \n",
    "                                               host='https://api.ubiops.com/v2.1'))\n",
    "api = ubiops.CoreApi(client)\n",
    "api.service_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's define some handy variables we willl be needing often. Please also define the name of your credential json here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment configurations\n",
    "GSHEET_COLLECTOR_DEPLOYMENT='gsheet-data-collector'\n",
    "RFM_DEPLOYMENT='rfm-model'\n",
    "GSHEET_WRITER_DEPLOYMENT='gsheet-write-results'\n",
    "DEPLOYMENT_VERSION='v1'\n",
    "deployments_list = [GSHEET_COLLECTOR_DEPLOYMENT, RFM_DEPLOYMENT, GSHEET_WRITER_DEPLOYMENT]\n",
    "\n",
    "# Pipeline configurations\n",
    "PIPELINE_NAME = 'gsheet-pipeline'\n",
    "PIPELINE_VERSION = 'v1'\n",
    "\n",
    "# Your Google credential json\n",
    "json_filename = '<YOUR JSON FILENAME>' # i.e. 'training-project-2736625.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"gsheet_input_connector\")\n",
    "os.mkdir(\"gsheet_output_connector\")\n",
    "os.mkdir(\"rfm-analysis-package\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the deployment.py for the data collector\n",
    "\n",
    "In the cell below we create the deployment.py for retrieving data from the google sheet we made earlier. The other files we already prepared in the `gsheet_input_connector` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gsheet_input_connector/deployment.py\n",
    "\"\"\"\n",
    "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
    "class and 'request' method.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "import pygsheets\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "class Deployment:\n",
    "\n",
    "    def __init__(self, base_directory, context):\n",
    "\n",
    "        print('Initialising the connection to the google drive')\n",
    "        self.gc = None\n",
    "\n",
    "        SCOPES = ('https://googleapis.com/auth/spreadsheets', 'https://googleapis.com/auth/drive')\n",
    "        service_account_info = json.loads(os.environ['credentials'])\n",
    "        my_credentials = service_account.Credentials.from_service_account_info(service_account_info, scopes=SCOPES)\n",
    "\n",
    "        try:\n",
    "            self.gc = pygsheets.authorize(custom_credentials=my_credentials)\n",
    "            print('Established succesfull connection')\n",
    "        except Exception as e:\n",
    "            print('Connection failed, ', e.__class__, 'occurred.')\n",
    "\n",
    "    def request(self, data):\n",
    "\n",
    "        print('Getting the requested file')\n",
    "        spreadsheet = self.gc.open(data['filename'])\n",
    "        sheet_data = spreadsheet[0]\n",
    "\n",
    "        # UbiOps expects JSON serializable output or files, so we pickle the data\n",
    "        with open('tmp_sheet.joblib', 'wb') as f:\n",
    "           dump(sheet_data, 'tmp_sheet.joblib')\n",
    "        \n",
    "        return {'data': 'tmp_sheet.joblib'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gsheet_input_connector/requirements.txt\n",
    "\n",
    "cachetools==4.2.2\n",
    "certifi==2020.12.5\n",
    "chardet==4.0.0\n",
    "google-api-core==1.28.0\n",
    "google-api-python-client==2.5.0\n",
    "google-auth==1.30.0\n",
    "google-auth-httplib2==0.1.0\n",
    "google-auth-oauthlib==0.4.4\n",
    "googleapis-common-protos==1.53.0\n",
    "httplib2==0.19.1\n",
    "idna==2.10\n",
    "joblib==1.0.1\n",
    "numpy==1.20.3\n",
    "oauthlib==3.1.0\n",
    "packaging==20.9\n",
    "protobuf==3.17.0\n",
    "pyasn1==0.4.8\n",
    "pyasn1-modules==0.2.8\n",
    "pygsheets==2.0.5\n",
    "pyparsing==2.4.7\n",
    "pytz==2021.1\n",
    "requests==2.25.1\n",
    "requests-oauthlib==1.3.0\n",
    "rsa==4.7.2\n",
    "six==1.16.0\n",
    "uritemplate==3.0.1\n",
    "urllib3==1.26.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the data collector\n",
    "\n",
    "Now that our deployment package is ready we can deploy it to UbiOps. In the following cells we define the deployment and upload the code to UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "    description='Collects data from a google sheet.',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[{'name':'filename', 'data_type':'string'}],\n",
    "    output_fields=[{'name':'data', 'data_type':'file'}]\n",
    ")\n",
    "\n",
    "deployment = api.deployments_create(project_name=PROJECT_NAME, data=deployment_template)\n",
    "print(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    environment='python3-7',\n",
    "    instance_type='256mb',\n",
    "    maximum_instances=1,\n",
    "    minimum_instances=0,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # We don't need request storage\n",
    ")\n",
    "\n",
    "version = api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "    data=version_template\n",
    ")\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the required environment variable and zip and upload the code package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the credentials json into a string\n",
    "with open(json_filename) as json_file:\n",
    "    cred_json = json_file.read().strip()\n",
    "\n",
    "# Create the environment variable to contain the credentials\n",
    "env_var_response = api.deployment_environment_variables_create(\n",
    "    project_name=PROJECT_NAME,        \n",
    "    deployment_name=GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "    data= {\n",
    "      \"name\": \"credentials\",\n",
    "      \"value\": cred_json,\n",
    "      \"secret\": True\n",
    "    }\n",
    ")\n",
    "print(env_var_response)\n",
    "\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive('gsheet_input_connector', 'zip', '.', 'gsheet_input_connector')\n",
    "\n",
    "upload_response1 = api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='gsheet_input_connector.zip'\n",
    ")\n",
    "print(upload_response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now there should be a deployment called `gsheet-data-collector` visible in the WebApp under the deployments tab. It should have one version that is building or available. While that one is building we can continue to create the other deployments we need.\n",
    "\n",
    "## Creating the RFM deployment\n",
    "\n",
    "First we have to create the deployment.py we need, which we do in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile rfm-analysis-package/deployment.py\n",
    "\"\"\"\n",
    "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
    "class and 'request' method.\n",
    "\"\"\"\n",
    "\n",
    "import pygsheets\n",
    "from joblib import load, dump\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Deployment:\n",
    "\n",
    "    def __init__(self, base_directory, context):\n",
    "\n",
    "        print('Initalizing model')\n",
    "\n",
    "    def request(self, data):\n",
    "\n",
    "        print('Loading the data')\n",
    "        sheet_data = load(data['retail_data'])\n",
    "\n",
    "        # Transforming it into a Pandas DataFrame\n",
    "        data_df = sheet_data.get_as_df()\n",
    "\n",
    "        # RFM analyis\n",
    "        print('Performing RFM analysis')\n",
    "        data_df['TotalPrice'] = data_df['Quantity'].astype(int) * data_df['UnitPrice'].astype(float)\n",
    "        data_df['InvoiceDate'] = pd.to_datetime(data_df['InvoiceDate'])\n",
    "\n",
    "        rfm= data_df.groupby('CustomerID').agg({'InvoiceDate': lambda date: (date.max() - date.min()).days,\n",
    "                                                'InvoiceNo': lambda num: len(num),\n",
    "                                                'TotalPrice': lambda price: price.sum()})\n",
    "\n",
    "        # Change the name of columns\n",
    "        rfm.columns=['recency','frequency','monetary']\n",
    "\n",
    "        # Computing Quantile of RFM values\n",
    "        rfm['recency'] = rfm['recency'].astype(int)\n",
    "        rfm['r_quartile'] = pd.qcut(rfm['recency'].rank(method='first'), 4, ['1','2','3','4']).astype(int)\n",
    "        rfm['f_quartile'] = pd.qcut(rfm['frequency'], 4, ['4','3','2','1']).astype(int)\n",
    "        rfm['m_quartile'] = pd.qcut(rfm['monetary'], 4, ['4','3','2','1']).astype(int)\n",
    "\n",
    "        rfm['RFM_Score'] = rfm.r_quartile.astype(str)+ rfm.f_quartile.astype(str) + rfm.m_quartile.astype(str)\n",
    "\n",
    "        # Filter out Top/Best customers\n",
    "        print('Filtering out top customers')\n",
    "        top_customers = rfm[rfm['RFM_Score']=='111'].sort_values('monetary', ascending=False)        \n",
    "\n",
    "        # UbiOps expects JSON serializable output or files, so we pickle the data\n",
    "        with open('top_customers.joblib', 'wb') as f:\n",
    "           dump(top_customers, 'top_customers.joblib')\n",
    "        \n",
    "        return {'top_customers': 'top_customers.joblib'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile rfm-analysis-package/requirements.txt\n",
    "joblib==1.0.1\n",
    "numpy==1.20.3\n",
    "pygsheets==2.0.5\n",
    "pandas==1.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before for the collector, we create the deployment for the rfm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=RFM_DEPLOYMENT,\n",
    "    description='RFM analysis that filters out the top customers.',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[{'name':'retail_data', 'data_type':'file'}],\n",
    "    output_fields=[{'name':'top_customers', 'data_type':'file'}]\n",
    ")\n",
    "\n",
    "deployment = api.deployments_create(project_name=PROJECT_NAME, data=deployment_template)\n",
    "print(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    environment='python3-8',\n",
    "    instance_type='1024mb',\n",
    "    maximum_instances=1,\n",
    "    minimum_instances=0,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # We do not need request storage\n",
    ")\n",
    "\n",
    "version = api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=RFM_DEPLOYMENT,\n",
    "    data=version_template\n",
    ")\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the deployment package\n",
    "shutil.make_archive('rfm-analysis-package', 'zip', '.', 'rfm-analysis-package')\n",
    "\n",
    "upload_response2 = api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=RFM_DEPLOYMENT,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='rfm-analysis-package.zip'\n",
    ")\n",
    "print(upload_response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFM model should now also be building in your UbiOps environment. Time to move on to the last deployment we need, the output connector.\n",
    "\n",
    "## Deploying the output connector\n",
    "\n",
    "Just like before we will first create a deployment.py, then a deployment and the required environment variables, after which we upload the code to UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gsheet_output_connector/deployment.py\n",
    "\"\"\"\n",
    "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
    "class and 'request' method.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "import pygsheets\n",
    "from joblib import load\n",
    "import pandas\n",
    "\n",
    "\n",
    "class Deployment:\n",
    "\n",
    "    def __init__(self, base_directory, context):\n",
    "\n",
    "        print('Initialising the connection to the google drive')\n",
    "        self.gc = None\n",
    "\n",
    "        SCOPES = ('https://googleapis.com/auth/spreadsheets', 'https://googleapis.com/auth/drive')\n",
    "        service_account_info = json.loads(os.environ['credentials'])\n",
    "        my_credentials = service_account.Credentials.from_service_account_info(service_account_info, scopes=SCOPES)\n",
    "\n",
    "        try:\n",
    "            self.gc = pygsheets.authorize(custom_credentials=my_credentials)\n",
    "            print('Established succesfull connection')\n",
    "        except Exception as e:\n",
    "            print('Connection failed, ', e.__class__, 'occurred.')\n",
    "\n",
    "    def request(self, data):\n",
    "\n",
    "        print('Loading top customers')\n",
    "        top_customers = load(data['data'])\n",
    "\n",
    "        print('Inserting data into the google sheet')\n",
    "        spreadsheet = self.gc.open(os.environ['filename'])\n",
    "        sheet_title = os.environ['sheet_title']\n",
    "\n",
    "        try:\n",
    "            sh = spreadsheet.worksheet_by_title(sheet_title)\n",
    "        except:\n",
    "            print('Worksheet does not exist, adding new sheet')\n",
    "            spreadsheet.add_worksheet(sheet_title)\n",
    "            sh = spreadsheet.worksheet_by_title(sheet_title)\n",
    "        finally:\n",
    "            sh.set_dataframe(top_customers, 'A1', copy_index = True)\n",
    "            sh.update_value('A1', 'CustomerID')\n",
    "            print('Data inserted successfully')     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gsheet_output_connector/requirements.txt\n",
    "\n",
    "google-api-core==1.28.0\n",
    "google-api-python-client==2.5.0\n",
    "google-auth==1.30.0\n",
    "google-auth-httplib2==0.1.0\n",
    "google-auth-oauthlib==0.4.4\n",
    "googleapis-common-protos==1.53.0\n",
    "joblib==1.0.1\n",
    "numpy==1.20.3\n",
    "oauthlib==3.1.0\n",
    "pygsheets==2.0.5\n",
    "pandas==1.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    description='Gsheet output connector',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[{'name':'data', 'data_type':'file'}],\n",
    "    output_fields=[]\n",
    ")\n",
    "\n",
    "deployment = api.deployments_create(project_name=PROJECT_NAME, data=deployment_template)\n",
    "print(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    environmentent='python3-7',\n",
    "    instance_type='1024mb',\n",
    "    maximum_instances=1,\n",
    "    minimum_instances=0,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # We don't need request storage\n",
    ")\n",
    "\n",
    "version = api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    data=version_template\n",
    ")\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment variable to contain the credentials\n",
    "env_var_response = api.deployment_environment_variables_create(\n",
    "    project_name=PROJECT_NAME,        \n",
    "    deployment_name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    data= {\n",
    "      'name': 'credentials',\n",
    "      'value': cred_json,\n",
    "      'secret': True\n",
    "    }\n",
    ")\n",
    "print(env_var_response)\n",
    "\n",
    "# Create the environment variable for the filename\n",
    "env_var_response = api.deployment_environment_variables_create(\n",
    "    project_name=PROJECT_NAME,        \n",
    "    deployment_name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    data= {\n",
    "      'name': 'filename',\n",
    "      'value': 'OnlineRetail',\n",
    "      'secret': False\n",
    "    }\n",
    ")\n",
    "print(env_var_response)\n",
    "\n",
    "# Create the environment variable for the sheet title\n",
    "# This is the sheet to which the results will be written\n",
    "env_var_response = api.deployment_environment_variables_create(\n",
    "    project_name=PROJECT_NAME,        \n",
    "    deployment_name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    data= {\n",
    "      'name': 'sheet_title',\n",
    "      'value': 'Top Customers',\n",
    "      'secret': False\n",
    "    }\n",
    ")\n",
    "print(env_var_response)\n",
    "\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive('gsheet_output_connector', 'zip', '.', 'gsheet_output_connector')\n",
    "\n",
    "upload_response3 = api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='gsheet_output_connector.zip'\n",
    ")\n",
    "print(upload_response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting for the deployments to finish building\n",
    "\n",
    "Right now all three deployments are building, and we need to wait until they are available before we proceed. The following while loop checks if they are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubiops.utils.wait_for_deployment_version(\n",
    "    client=api.api_client,\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    revision_id=upload_response1.revision\n",
    ")\n",
    "\n",
    "ubiops.utils.wait_for_deployment_version(\n",
    "    client=api.api_client,\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=RFM_DEPLOYMENT,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    revision_id=upload_response2.revision\n",
    ")\n",
    "\n",
    "ubiops.utils.wait_for_deployment_version(\n",
    "    client=api.api_client,\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=GSHEET_WRITER_DEPLOYMENT,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    revision_id=upload_response3.revision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the pipeline\n",
    "\n",
    "Now that we have our three deployments we can connect them together in a pipeline. Our pipeline will first call the data collector, then the RFM analysis and lastly it will write away the results to a separate sheet in the google spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_template = ubiops.PipelineCreate(\n",
    "    name=PIPELINE_NAME,\n",
    "    description='A simple pipeline that performs an RFM analysis on retail data from a google sheet.',\n",
    "    input_type='structured',\n",
    "    input_fields=[{'name':'filename', 'data_type':'string'}],\n",
    "    output_type='structured',\n",
    "    output_fields=[]\n",
    ")\n",
    "\n",
    "api.pipelines_create(project_name=PROJECT_NAME, data=pipeline_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the pipeline version\n",
    "\n",
    "Now that we have a pipeline, we can create a version with the actual deployments in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_template = ubiops.PipelineVersionCreate(\n",
    "    version=PIPELINE_VERSION,\n",
    "    request_retention_mode='full',\n",
    "    objects=[\n",
    "        # input connector\n",
    "        {\n",
    "            'name': GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "            'reference_name': GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "            'version': DEPLOYMENT_VERSION\n",
    "        },\n",
    "        # RFM model\n",
    "        {\n",
    "            'name': RFM_DEPLOYMENT,\n",
    "            'reference_name': RFM_DEPLOYMENT,\n",
    "            'version': DEPLOYMENT_VERSION\n",
    "        },\n",
    "        # output connector\n",
    "        {\n",
    "            'name': GSHEET_WRITER_DEPLOYMENT,\n",
    "            'reference_name': GSHEET_WRITER_DEPLOYMENT,\n",
    "            'version': DEPLOYMENT_VERSION\n",
    "        }\n",
    "    ],\n",
    "    attachments=[\n",
    "        # start --> data collector\n",
    "        {\n",
    "            'destination_name': GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "            'sources': [{\n",
    "                'source_name': 'pipeline_start',\n",
    "                'mapping': [{\n",
    "                    \"source_field_name\": 'filename',\n",
    "                    'destination_field_name': 'filename'\n",
    "                }]\n",
    "            }]\n",
    "        },\n",
    "        # Data collector -> RFM model\n",
    "        {\n",
    "            'destination_name': RFM_DEPLOYMENT,\n",
    "            'sources': [{\n",
    "                'source_name': GSHEET_COLLECTOR_DEPLOYMENT,\n",
    "                'mapping': [{\n",
    "                    \"source_field_name\": 'data',\n",
    "                    'destination_field_name': 'retail_data'\n",
    "                }]\n",
    "            }]\n",
    "        },\n",
    "        # RFM model -> output connector\n",
    "        {\n",
    "            'destination_name': GSHEET_WRITER_DEPLOYMENT,\n",
    "            'sources': [{\n",
    "                'source_name': RFM_DEPLOYMENT,\n",
    "                'mapping': [{\n",
    "                    \"source_field_name\": 'top_customers',\n",
    "                    'destination_field_name': 'data'\n",
    "                }]\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "api.pipeline_versions_create(project_name=PROJECT_NAME, pipeline_name=PIPELINE_NAME, data=pipeline_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well you should have a pipeline that looks like this:\n",
    "\n",
    "![pipeline](https://storage.googleapis.com/ubiops/data/Integration%20with%20other%20tools/gsheet-rfm-pipeline/pictures/pipeline.png)\n",
    "\n",
    "\n",
    "## Making a request\n",
    "\n",
    "With our pipeline done, we can send a request to it perform the RFM analysis on our OnlineRetail sheet! Run the cell below to do so.\n",
    "The RFM analysis is not that fast so the request might take a little while to complete. You can check the logs in the WebApp to see what is going on in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'filename':'OnlineRetail'}\n",
    "pipeline_result = api.pipeline_version_requests_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    version=PIPELINE_VERSION,\n",
    "    data=data\n",
    ")\n",
    "print(pipeline_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring further\n",
    "You can go ahead to the WebApp and take a look in the user interface at what you have just built and explore further.\n",
    "\n",
    "So there we have it! We have created a pipeline that itneracts with a Google Sheet. You can use this notebook to base your own deployments on. Just adapt the code in the deployment packages and alter the input and output fields as you wish and you should be good to go.\n",
    "\n",
    "For any questions, feel free to reach out to us via the customer service portal: https://ubiops.atlassian.net/servicedesk/customer/portals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling the service account\n",
    "\n",
    "Tip: disable or delete your service account in the google console if you do not plan on using it anymore. You can do so by navigating to the service account and clicking \"Disable service account\", or \"Delete service account\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "environment": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "metadata": {
   "interpreter": {
    "hash": "9e5e316876f34c24fc8fbb6ab4f19009cacc0a30c8625f18eb8a466999e49887"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "9b956f356e97532e124a78bf3abf58bc4abb2e20db909e5dd1c0cfe7d3a45a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
