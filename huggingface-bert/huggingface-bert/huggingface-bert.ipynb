{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-yetF3Srnk3"
      },
      "source": [
        "# Deploying the BERT Transformer model to UbiOps\n",
        "\n",
        "This notebook will help you create a cloud-based inference API endpoint for BERT, using UbiOps. The model we have is \n",
        "already pretrained and will be loaded from the Huggingface Transformers library. The workflow of this notebook can be used for other Huggingface models as well. We use the BERT model in this example, because it can run on a small CPU instance type. \n",
        "\n",
        "In the following sections we will walk you through:\n",
        "\n",
        "- Connecting with the UbiOps API client\n",
        "- Creating a new UbiOps \"deployment\" with the BERT model\n",
        "- How to call the BERT model with the model API\n",
        "\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "## 1. Installing the UbiOps client library\n",
        "To interface with UbiOps through code we need the UbiOps Python client library. In the following cell it will be installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBDhY41Hw6pz"
      },
      "outputs": [],
      "source": [
        "!pip install ubiops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBQfwWt4rnk4"
      },
      "source": [
        "## 2. Defining project info and setting up a connection\n",
        "\n",
        "First, make sure you create an API token with `project-editor` permissions in your UbiOps project and paste it below. \n",
        "Also, fill in your corresponding UbiOps project name.\n",
        "\n",
        "Once you have your project name and API token, paste them in the right spot in the following cell before running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcMtxyTvrnk4"
      },
      "outputs": [],
      "source": [
        "import ubiops\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "API_TOKEN = '<INSERT API_TOKEN WITH PROJECT EDITOR RIGHTS>' # Make sure this is in the format \"Token token-code\"\n",
        "PROJECT_NAME = '<INSERT PROJECT NAME IN YOUR ACCOUNT>' # Fill in your project name here \n",
        "\n",
        "DEPLOYMENT_NAME = f\"bert-base-uncased-{datetime.now().date()}\"\n",
        "DEPLOYMENT_VERSION = 'v1'\n",
        "UBIOPS_STORAGE_BUCKET = 'default'\n",
        "\n",
        "# Initialize client library\n",
        "configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
        "configuration.api_key['Authorization'] = API_TOKEN\n",
        "\n",
        "# Establish a connection\n",
        "client = ubiops.ApiClient(configuration)\n",
        "api = ubiops.CoreApi(client)\n",
        "print(api.projects_get(PROJECT_NAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSTlQ2iKy02n"
      },
      "source": [
        "## 3. Preparing the deployment code\n",
        "\n",
        "Now that we have defined our deployment in UbiOps, it is time to write our code to push it to UbiOps. Running the following cells will do that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOqhWrwpy9Sn"
      },
      "outputs": [],
      "source": [
        "!mkdir deployment_package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMEXa3kLrnk8"
      },
      "source": [
        "### a) Requirements.txt file\n",
        "\n",
        "The `requirements.txt` file lists all the necessary packages that have to be installed in the environment. UbiOps will \n",
        "do this for you automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGKxscOizDa9"
      },
      "outputs": [],
      "source": [
        "%%writefile deployment_package/requirements.txt\n",
        "# This file contains package requirements for the deployment\n",
        "# installed via PIP. Installed before deployment initialization\n",
        "\n",
        "ubiops\n",
        "numpy\n",
        "torch==1.13.1\n",
        "transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p2abDzOrnk8"
      },
      "source": [
        "### b) Deployment.py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVc7RSszrnk8"
      },
      "source": [
        "For this example we create the code files and the deployment package directly from this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN91noM2rnk9"
      },
      "source": [
        "The `deployment.py` is the file that contains the code that will run on UbiOps each time a request is made. In this case the deployment is used to run the BERT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9LxAbVQy94E"
      },
      "outputs": [],
      "source": [
        "%%writefile deployment_package/deployment.py\n",
        "\n",
        "\"\"\"\n",
        "The file containing the deployment code needs to be called 'deployment.py' and should contain a 'Deployment'\n",
        "class a 'request' method.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import ubiops\n",
        "from transformers import AutoTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "import shutil\n",
        "\n",
        "\n",
        "class Deployment:\n",
        "\n",
        "    def __init__(self, base_directory, context):\n",
        "        \"\"\"\n",
        "        Initialisation method for the deployment. Any code inside this method will execute when the deployment starts up.\n",
        "        It can for example be used for loading modules that have to be stored in memory or setting up connections.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Initialising deployment\")\n",
        "        \n",
        "        configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
        "        configuration.api_key['Authorization'] = os.environ['API_TOKEN']\n",
        "        client = ubiops.ApiClient(configuration)\n",
        "        api_client = ubiops.CoreApi(client)\n",
        "        project_name = os.environ['PROJECT_NAME']\n",
        "\n",
        "        tok_fn = \"bert-base-uncased-tok\"\n",
        "        model_fn = \"bert-base-uncased-model\"\n",
        "        \n",
        "        try:\n",
        "            ubiops.utils.download_file(\n",
        "                        client,\n",
        "                        project_name,\n",
        "                        bucket_name=\"default\", \n",
        "                        file_name=f\"{tok_fn}.zip\",\n",
        "                        output_path=\".\",\n",
        "                        stream=True,\n",
        "                        chunk_size=8192\n",
        "                        )\n",
        "\n",
        "            shutil.unpack_archive(f\"{tok_fn}.zip\",f\"./{tok_fn}\", 'zip')\n",
        "            print(\"Token file loaded from object storage\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(f\"./{tok_fn}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"Tokenizer does not exist. Downloading from Hugging Face\")\n",
        "\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "            self.tokenizer.save_pretrained(f\"./{tok_fn}\")\n",
        "            tok_dir = shutil.make_archive(tok_fn, 'zip', tok_fn)\n",
        "            ubiops.utils.upload_file(client, project_name, f\"{tok_fn}.zip\", 'default')\n",
        "        \n",
        "        try:\n",
        "            ubiops.utils.download_file(\n",
        "                        client,\n",
        "                        project_name,\n",
        "                        bucket_name='default', \n",
        "                        file_name=f\"{model_fn}.zip\",\n",
        "                        output_path='.',\n",
        "                        stream=True,\n",
        "                        chunk_size=8192\n",
        "                        )\n",
        "\n",
        "            shutil.unpack_archive(f\"{model_fn}.zip\",f\"./{model_fn}\", 'zip')\n",
        "            print(\"Model file loaded from object storage\")\n",
        "            self.model = BertForMaskedLM.from_pretrained(f\"./{model_fn}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"Model does not exist. Downloading from Hugging Face\")\n",
        "\n",
        "            self.model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "            self.model.save_pretrained(f\"./{model_fn}\")\n",
        "\n",
        "            print(\"Storing model on UbiOps\")\n",
        "            model_dir = shutil.make_archive(model_fn, 'zip', model_fn)\n",
        "            ubiops.utils.upload_file(client, project_name, f\"{model_fn}.zip\", \"default\")\n",
        "            \n",
        "\n",
        "    def request(self, data):\n",
        "        \"\"\"\n",
        "        Method for deployment requests, called separately for each individual request.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Processing request\")\n",
        "\n",
        "        inputs = self.tokenizer(data[\"sentence\"], return_tensors=\"pt\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "\n",
        "        # retrieve index of [MASK]\n",
        "        mask_token_index = (inputs.input_ids == self.tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "\n",
        "        predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
        "        result = self.tokenizer.decode(predicted_token_id)\n",
        "\n",
        "        # here we set our output parameters in the form of a json\n",
        "        return {\"prediction\": result}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXtg0qh7ydZm"
      },
      "source": [
        "## 4. Creating a UbiOps deployment\n",
        "\n",
        "Now that we have our code ready, we can create a deployment.\n",
        "\n",
        "We have set up this deployment in such a way that it expects a sentence as a string, with one word hidden with `[MASK]`. \n",
        "The output of the deployment will be the prediction for the value of the mask.\n",
        "\n",
        "|Deployment input & output variables| | |\n",
        "|--------------------|--------------|----|\n",
        "| | **Variable name**| **Data type**|\n",
        "| **Input fields** | sentence | string |\n",
        "| **Output fields** | prediction | |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUbHzsSbyhgC"
      },
      "outputs": [],
      "source": [
        "# Create the deployment\n",
        "deployment_template = ubiops.DeploymentCreate(\n",
        "    name=DEPLOYMENT_NAME,\n",
        "    input_type='structured',\n",
        "    output_type='structured',\n",
        "    input_fields=[{'name': 'sentence', 'data_type': 'string'}],\n",
        "    output_fields=[{'name': 'prediction', 'data_type': 'string'}]\n",
        ")\n",
        "\n",
        "api.deployments_create(project_name=PROJECT_NAME, data=deployment_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gou_ZJxZrnk9"
      },
      "source": [
        "### Create a deployment version\n",
        "\n",
        "Now we will create a version of the deployment. For the version we need to define the name, Python version, the type of instance (CPU or GPU) as well the size of the instance.\n",
        "\n",
        "**For this we will use Python 3.10 with sufficient memory. Optionally you can run on a GPU which will speed up the inference, please [contact us](https://ubiops.com/contact-us/) if you want to enable this for your organization.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IQDht-Krnk-"
      },
      "outputs": [],
      "source": [
        "# Let's first create the version\n",
        "version_template = ubiops.DeploymentVersionCreate(\n",
        "    version=DEPLOYMENT_VERSION,\n",
        "    environment='python3-10',\n",
        "    instance_type= '2048mb',\n",
        "    maximum_instances=1,\n",
        "    minimum_instances=0,\n",
        "    maximum_idle_time=600, # = 10 minutes\n",
        "    request_retention_mode='full'\n",
        ")\n",
        "\n",
        "api.deployment_versions_create(project_name=PROJECT_NAME, deployment_name=DEPLOYMENT_NAME, data=version_template)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create environment variable\n",
        "\n",
        "We need to create two environment variables, one for the API token and one for the project name. With these environment\n",
        "variables we can upload the tokenizer and model from the initialization method in the `deployment.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_response = api.deployment_environment_variables_create(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    data=ubiops.EnvironmentVariableCreate(\n",
        "        name='API_TOKEN',\n",
        "        value=API_TOKEN,\n",
        "        secret=True\n",
        "))\n",
        "\n",
        "api_response = api.deployment_environment_variables_create(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    data=ubiops.EnvironmentVariableCreate(\n",
        "        name='PROJECT_NAME',\n",
        "        value=PROJECT_NAME,\n",
        "        secret=True\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnD5H2onrnk-"
      },
      "source": [
        "## 5. Package and upload the code\n",
        "\n",
        "After defining the deployment and version, we can upload the code to UbiOps. We zip and upload the folder containing the\n",
        "`requirements.txt` and `deployment.py` files. As we do this, UbiOps will build a container based on the settings above \n",
        " and install all packages defined in our requirements file.\n",
        "\n",
        "**Note** This step might take a few minutes, you can monitor the progress in the UbiOps WebApp by navigating to the \n",
        "deployment version and click the `logs` icon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7x9Gi7xOHSf"
      },
      "outputs": [],
      "source": [
        "# And now we zip our code (deployment package) and push it to the version\n",
        "\n",
        "import shutil\n",
        "zip_dir = shutil.make_archive(\"deployment_package\", 'zip', 'deployment_package')\n",
        "\n",
        "upload_response = api.revisions_file_upload(\n",
        "    project_name=PROJECT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    version=DEPLOYMENT_VERSION,\n",
        "    file='deployment_package.zip'\n",
        ")\n",
        "print(upload_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFYSAI3rnk-"
      },
      "source": [
        "### Wait for the deployment to be ready\n",
        "\n",
        "And now we just wait until the deployment is ready for use! It needs to build the container for a few minutes first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSWVuq89rnk-"
      },
      "outputs": [],
      "source": [
        "# Wait for the deployment version to be available\n",
        "\n",
        "\n",
        "ubiops.utils.wait_for_deployment_version(api.api_client, PROJECT_NAME, DEPLOYMENT_NAME, DEPLOYMENT_VERSION, \n",
        "revision_id= upload_response.revision)\n",
        "\n",
        "print(\"Deployment version is available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZCNhtuprnk-"
      },
      "source": [
        "## 6. Create a request to the model API on UbiOps to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9jeHwuQM1t8"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"sentence\": \"Paris is the capital of [MASK].\",\n",
        "}\n",
        "\n",
        "api.deployment_requests_create(\n",
        "    project_name=PROJECT_NAME, deployment_name=DEPLOYMENT_NAME, data=data\n",
        ").result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Wrapping up\n",
        "\n",
        "And there you have it! We have succesfully created a deployment that uses a BERT model that was loaded from Huggingface.\n",
        "\n",
        "Now all that is left to do is to close the connection to the UbiOps API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
