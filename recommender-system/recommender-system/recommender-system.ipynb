{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a recommender model\n",
    "**Note**: This notebook runs on Python 3.11 and uses UbiOps CLient Library 3.15.0. It is used in [this blogpost](https://ubiops.com/how-to-build-and-implement-a-recommendation-system-from-scratch-in-python/).\n",
    "\n",
    "In this notebook we will show you the following:\n",
    "- how to train a recommender model on shopping data using [the Apriori algorithm](https://en.wikipedia.org/wiki/Apriori_algorithm)\n",
    "- How to deploy that model to UbiOps\n",
    "\n",
    "Recommender models are everywhere nowadays. At every webshop you will receive suggestions based on products you have viewed or added to your shopping cart. In this notebook we will make such a recommender model that can be used in the backend of a webshop. We will use the Apriori algorithm to find rules that describe associations between different products given 7500 transactions over the course of a week at a French retail store. The dataset can be downloaded [here](https://drive.google.com/file/d/1y5DYn0dGoSbC22xowBq2d4po6h1JxcTQ/view).\n",
    "\n",
    "If you run this entire notebook after filling in your access token, the model is trained and deployed to your UbiOps environment. You can thus check your environment after running to explore. You can also check the individual steps in this notebook to see what we did exactly and how you can adapt it to your own use case.\n",
    "\n",
    "We recommend to run the cells step by step, as some cells can take a few minutes to finish. You can run everything in one go as well and it will work, just allow a few minutes for building the individual deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's install and import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install apyori \n",
    "!pip install matplotlib \n",
    "!pip install numpy \n",
    "!pip install pandas \n",
    "!pip install ubiops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import shutil\n",
    "import os\n",
    "import ubiops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a connection with your UbiOps environment\n",
    "Add your API token and project name below. Afterwards we initialize the client library. This way we can deploy the model to your environment once we have trained it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up connection to UbiOps\n",
    "API_TOKEN = '<INSERT API_TOKEN WITH PROJECT EDITOR RIGHTS>' # Make sure this is in the format \"Token token-code\"\n",
    "PROJECT_NAME= '<INSERT PROJECT NAME IN YOUR ACCOUNT>'\n",
    "DEPLOYMENT_NAME='recommender-model'\n",
    "DEPLOYMENT_VERSION='v1'\n",
    "\n",
    "client = ubiops.ApiClient(ubiops.Configuration(api_key={'Authorization': API_TOKEN}, \n",
    "                                               host='https://api.ubiops.com/v2.1'))\n",
    "api = ubiops.CoreApi(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and preprocess\n",
    "\n",
    "In the next cell we take a look at the data via head(). Don't worry about all the NaN values, this has to do with the ype of data we are dealing with. Our csv file contains orders made by customers. These orders vary a lot, some only buy 3 items, whereas others buy 20. Since a dataframe has a fixed size it takes the size of the longest order and fills up the rest with NaNs. In the preprocessing step we filter out these NaN's when we convert the dataframe to alist of lists, the input format the Apriori algorithm needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = pd.read_csv('store_data.csv', header=None)\n",
    "store_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = store_data.shape\n",
    "n_of_transactions = df_shape[0]\n",
    "n_of_products = df_shape[1]\n",
    "\n",
    "# Converting our dataframe into a list of lists for Apriori algorithm\n",
    "records = []\n",
    "for i in range(0, n_of_transactions):\n",
    "    records.append([])\n",
    "    for j in range(0, n_of_products):\n",
    "        if (str(store_data.values[i,j]) != 'nan'):\n",
    "            records[i].append(str(store_data.values[i,j]))\n",
    "        else :\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find association rules with Apriori algorithm\n",
    "\n",
    "Now that the data is ready we can run the apriori algorithm on our data to find association rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the apriori algorithm\n",
    "association_rules = apriori(records, min_support=0.0045, min_confidence=0.2, min_lift=2, max_length=5)\n",
    "association_results = list(association_rules)\n",
    "\n",
    "# Check how many rules were found\n",
    "print(len(association_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found our association rules we need to use that to build up a small database that we can query for recommendations. What we want is a database that we can query for a certain product, and that returns three suggestions that a consumer of that product might also be interested in. However, not every association rule gives us three items that are frequently bought with the base item. To make sure that every query will return three recommendations, we will recommend the overall most frequently bought products to fill up the gaps. To do so, we will first have to rank all the products based on how frequently they appear in purchases in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the products listed in dataset\n",
    "# First merge all the columns of the data frame to a data series object\n",
    "merged = store_data[0]\n",
    "for i in range(1,n_of_products):\n",
    "    merged = merged.append(store_data[i])\n",
    "\n",
    "# Then rank all the unique products\n",
    "ranking = merged.value_counts(ascending=False)\n",
    "# Extract the products in order without their respective count\n",
    "ranked_products = list(ranking.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a ranking with of the products, and the association rules found by Apriori, we can set up our recommendation rules. In the following cell we also output the support, confidence and lift of the different rules. \n",
    "\n",
    "**Support:**\n",
    "Support refers to the default popularity of an item and can be calculated by finding number of transactions containing a particular item divided by total number of transactions. \n",
    "\n",
    "**Confidence:**\n",
    "Confidence refers to the likelihood that an item B is also bought if item A is bought. It can be calculated by finding the number of transactions where A and B are bought together, divided by total number of transactions where A is bought.\n",
    "\n",
    "**Lift:**\n",
    "`Lift(A -> B)` refers to the increase in the ratio of sale of B when A is sold. `Lift(A â€“> B)` can be calculated by dividing `Confidence(A -> B)` divided by `Support(B)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "lookup_table = {}\n",
    "for item in association_results:\n",
    "\n",
    "    # First index of the inner list contains base item and add item\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    to_print = \"Rule: \"\n",
    "    arrow = \" -> \"\n",
    "    for i in range(len(items)):\n",
    "        to_print += str(items[i]) + arrow\n",
    "        \n",
    "    # If we do not have 3 recommendations for our base product we will\n",
    "    # suggest top ranked products in addition\n",
    "    if len(items) < 4:\n",
    "        items_to_append = items\n",
    "        i = 0\n",
    "        while len(items) < 4:\n",
    "            if ranked_products[i] not in items:\n",
    "                items_to_append.append(ranked_products[i])\n",
    "            i += 1\n",
    "    \n",
    "    # Add the items to db, with base product separately from the products \n",
    "    # that are to be recommended\n",
    "    lookup_table[items_to_append[0]] =items_to_append[1:]\n",
    "\n",
    "    print(to_print)\n",
    "\n",
    "    # Print the support for this association rule\n",
    "    print(\"Support: \" + str(item[1]))\n",
    "\n",
    "    # Print the confidence and lift for this association rule\n",
    "\n",
    "    print(\"Confidence: \" + str(item[2][0][2]))\n",
    "    print(\"Lift: \" + str(item[2][0][3]))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dictionary does not contain recommendations for all products\n",
    "# In case we don't have a recommendation, the top 3 most frequently bought items \n",
    "# need to be suggested. Therefore we need an additional entry in our table\n",
    "lookup_table['default_recommendation'] = ranked_products[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we pickle the dictionary for later use in our deployed model\n",
    "with open('recommender_deployment_package/lookup_table.pickle', 'wb') as handle:\n",
    "    pickle.dump(lookup_table, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying recommender model to UbiOps\n",
    "\n",
    "We have generated our look up table for recommendations, based on the Apriori algorithm. Now we need to deploy a model to UbiOps that outputs recommendations based on this look up table. The deployment we made to do this can be found in the dpeloyment package as deployment.py. It is loaded below so you can take a look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile recommender_deployment_package/deployment.py\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Deployment:\n",
    "\n",
    "    def __init__(self, base_directory, context):\n",
    "        print(\"Initialising recommender model\")\n",
    "\n",
    "        lookup_table = os.path.join(base_directory, \"lookup_table.pickle\")\n",
    "        with open(lookup_table, 'rb') as handle:\n",
    "            self.lookup_table = pickle.load(handle)\n",
    "\n",
    "    def request(self, data):\n",
    "        print('Fetching recommendations')\n",
    "        input_product = data['clicked_product']\n",
    "        try:\n",
    "            recommendation = self.lookup_table[input_product]\n",
    "        except KeyError:\n",
    "            recommendation = self.lookup_table['default_recommendation']\n",
    "\n",
    "        return {\n",
    "            \"recommendation\": recommendation\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's deploy to UbiOps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up deployment template\n",
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    description='Recommmends other products to look at based on clicked product',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[\n",
    "        {'name':'clicked_product', 'data_type':'string'}\n",
    "    ],\n",
    "    output_fields=[\n",
    "        {'name':'recommendation', 'data_type':'array_string'}\n",
    "    ],\n",
    "    labels={'demo': 'recommender-system'}\n",
    ")\n",
    "\n",
    "api.deployments_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=deployment_template\n",
    ")\n",
    "\n",
    "# Create the version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    environment='python3-11',\n",
    "    instance_type_group_name='256 MB + 0.0625 vCPU',\n",
    "    minimum_instances=0,\n",
    "    maximum_instances=5,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # We don't need to store the requests in this demo\n",
    ")\n",
    "\n",
    "api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    data=version_template\n",
    ")\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive('recommender_deployment_package', 'zip', '.', 'recommender_deployment_package')\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "file_upload_result =api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='recommender_deployment_package.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All done! Let's close the client properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a request and exploring further\n",
    "You can go ahead to the Web App and take a look in the user interface at what you have just built. If you want you can create a request to deployment using any product from the original csv file as input, for instance `spaghetti`.  \n",
    "\n",
    "So there we have it! We have made a recommender model and deployed it to UbiOps. You can use this notebook as inspiration for your own recommender model. \n",
    "\n",
    "For any questions, feel free to reach out to us via the customer service portal: https://ubiops.atlassian.net/servicedesk/customer/portals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "environment": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
