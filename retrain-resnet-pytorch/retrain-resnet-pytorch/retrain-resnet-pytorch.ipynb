{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain ResNet using PyTorch\n",
    "\n",
    "In this example, we show how to retrain a PyTorch model on UbiOps. In this end-to-end example, we first set-up an `Environment` in which our training jobs can run. Then we define a `train.py` script that we can apply to our `Environment`. The training script imports ResNet with pretrained weights and retrains that model on the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). Finally, we benchmark its performance on the test set, and add that as a `metric` to our output. Snippets from this workflow can be used to retrain your own models.\n",
    "\n",
    "Let us first install the UbiOps Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"ubiops >= 3.15\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Set project variables and initialize the UbiOps API Client\n",
    "First, make sure you create an API token with project editor permissions in your UbiOps project and paste it below. Also fill in your corresponding UbiOps project name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import yaml\n",
    "import os\n",
    "import ubiops\n",
    "\n",
    "dt = datetime.now()\n",
    "\n",
    "API_TOKEN = 'Token '   # Paste your API token here. Don't forget the `Token` prefix\n",
    "PROJECT_NAME = ''  # Fill in the corresponding UbiOps project name\n",
    "\n",
    "configuration = ubiops.Configuration(host=\"https://api.ubiops.com/v2.1\")\n",
    "configuration.api_key['Authorization'] = API_TOKEN\n",
    "\n",
    "api_client = ubiops.ApiClient(configuration)\n",
    "core_instance = ubiops.CoreApi(api_client=api_client)\n",
    "training_instance = ubiops.Training(api_client=api_client)\n",
    "print(core_instance.service_status())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up a training instance in case you have not done this yet in your project. This action will create a base training deployment, that is used to host training experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance = ubiops.Training(api_client=api_client)\n",
    "try:\n",
    "    training_instance.initialize(project_name=PROJECT_NAME)\n",
    "except ubiops.exceptions.ApiException as e:\n",
    "    print(f\"The training feature may already have been initialized in your project:\\n{e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the code environment\n",
    "Our training code needs an environment to run in, with a specific Python language version, and some dependencies, like `PyTorch`. You can create and manage environments in your UbiOps project. We create an environment named `python3-11-pytorch-retraining`, select Python 3.11 and upload a requirements.txt which contains the relevant dependencies.\n",
    "\n",
    "The environment can be reused and updated for different training jobs (and deployments!). The details of the environment are visible in the 'environments' tab in the UbiOps UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_environment_dir = 'training_environment'\n",
    "ENVIRONMENT_NAME = 'python3-11-pytorch-retraining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir {training_environment_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {training_environment_dir}/requirements.txt\n",
    "torch==1.13.1\n",
    "torchvision==0.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "training_environment_archive = shutil.make_archive(f'{training_environment_dir}', 'zip', '.', f'{training_environment_dir}')\n",
    "\n",
    "# Create experiment. Your environment is set-up in this step. It may take some time to run.\n",
    "\n",
    "try:\n",
    "    api_response = core_instance.environments_create(\n",
    "        project_name=PROJECT_NAME,\n",
    "        data=ubiops.EnvironmentCreate(\n",
    "        name=ENVIRONMENT_NAME,\n",
    "        #display_name=ENVIRONMENT_NAME,\n",
    "        base_environment='python3-11',\n",
    "        description='Training environment with Python 3.11 and PyTorch 1.13 for Resnet retraining'        )\n",
    "    )\n",
    "\n",
    "    core_instance.environment_revisions_file_upload(\n",
    "        project_name=PROJECT_NAME,\n",
    "        environment_name=ENVIRONMENT_NAME,\n",
    "        file=training_environment_archive\n",
    "    )\n",
    "except ubiops.exceptions.ApiException as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure an experiment\n",
    "The basis for model training in UbiOps is an 'Experiment'. An experiment has a fixed code environment and hardware (instance) definition, but it can hold many different 'Runs'. You can create an experiment in the WebApp or use the client library, as we do here.\n",
    "\n",
    "This bucket will be used to store your training jobs, model artifacts and any other files that are created during the training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'retrain-resnet-pytorch' # str\n",
    "BUCKET_NAME = 'default'\n",
    "\n",
    "try:\n",
    "    experiment = training_instance.experiments_create(\n",
    "        project_name=PROJECT_NAME,\n",
    "        data=ubiops.ExperimentCreate(\n",
    "            instance_type_group_name='4096 MB + 1 vCPU',\n",
    "            description='Retrain the ResNet model on CIFAR-10 data',\n",
    "            name=EXPERIMENT_NAME,\n",
    "            environment=ENVIRONMENT_NAME,\n",
    "            default_bucket= BUCKET_NAME\n",
    "        )\n",
    "    )\n",
    "except ubiops.exceptions.ApiException as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and start a training run\n",
    "A training job in UbiOps is called a run. To run Python code for training on UbiOps, we need to create a file named `train.py` and include our training code here. This code will execute as a single 'Run' as part of an 'Experiment' and uses the code environment and instance type (hardware) as defined with the experiment as shown before.  \n",
    "Letâ€™s take a look at the training script. The `train.py` script requires a `train()` function, with input parameters `training_data` (a file path to your training data) and `parameters` (a dictionary that contains parameters of your choice). More detailed information on the training code format can be found in the [UbiOps training documentation](https://ubiops.com/docs/training/#training-code-format).  \n",
    " \n",
    "In this example, we will download the `CIFAR-10` dataset using the `torchvision` package during the training process, so there is no need to upload our own dataset.\n",
    "\n",
    "Now that we have our `environment` and `experiment` set-up, it is easy to initiate runs. The `RUN_NAME` and `RUN_SCRIPT` can easily be tweaked in the next two cells, and sent to the relevant `experiment` in the cell after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = 'training-run'\n",
    "RUN_SCRIPT = f'{RUN_NAME}.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {RUN_SCRIPT}\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "class Net(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Preload resnet. Supress logs while importing\n",
    "        self.model = models.resnet50(weights='ResNet50_Weights.DEFAULT', progress = False)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        #Apply our optimizer\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "   def forward(self, x, target=None):\n",
    "        x = self.model(x)\n",
    "\n",
    "        if self.training:\n",
    "            loss = self.loss(x, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            return x, loss\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "def train(training_data, parameters, context):\n",
    "    \n",
    "    # Check the availability of a GPU (this tutorial focuses on a CPU instance, \n",
    "    # but can be extended to run on a GPU instance)\n",
    "    print(torch.cuda.is_available())\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Get batch size from input parameters\n",
    "    batch_size = parameters['batch_size']\n",
    "    epochs = int(parameters['epochs'])\n",
    "    \n",
    "    print(f\"Unpacked parameters {parameters}\")\n",
    "    # Create data input transformer\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    " \n",
    "    # Select the dataset from torchvision\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=True,\n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=False,\n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        dataset=testset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        drop_last = True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    \n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    net = Net()\n",
    "    \n",
    "    net.to(device)\n",
    "    print(f\"Moved Resnet model to {device}\")\n",
    "    \n",
    "    print(\"Starting the model training!\")\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for _ , data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            _, loss = net(inputs, labels)\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(trainloader):.3f}')\n",
    "              \n",
    "    print(\"Finished model training\")\n",
    "\n",
    "    model_path =  \"./cifar_net.pth\"\n",
    "    # Return the trained model\n",
    "    torch.save(net.state_dict(), model_path)\n",
    "    print(f\"Saved model to {model_path} \")\n",
    "    \n",
    "    \n",
    "    print(\"Evaluating the model performance\")    \n",
    "    testnet = Net()\n",
    "    testnet.to(device)\n",
    "    testnet.load_state_dict(torch.load(model_path))\n",
    "    testnet.eval()\n",
    "    \n",
    "    # Test accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = testnet(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the retrained Resnet model on all 10000 test images: {100 * correct // total} %')\n",
    "    \n",
    "    run_id = context['id']\n",
    "    return {\n",
    "        \"artifact\": {\n",
    "            \"file\": \"cifar_net.pth\",\n",
    "            \"bucket\": os.environ.get(\"SYS_DEFAULT_BUCKET\", \"default\"),\n",
    "            \"bucket_file\": f\"{run_id}/cifar_net.pth\"\n",
    "        },\n",
    "        \"metrics\": json.dumps({\n",
    "            \"accuracy\": 100 * correct // total\n",
    "        })\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initiate the training run. Do note that each epoch takes around 15 minutes to finish on a 4GB CPU instance. For demonstration purposes, we will run 1 epoch only, but feel free to increase this number if you have the time. The workload is running in the cloud, so there is no need to keep your local machine on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run = training_instance.experiment_runs_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    data=ubiops.ExperimentRunCreate(\n",
    "        name=RUN_NAME,\n",
    "        description='First try!',\n",
    "        training_code= RUN_SCRIPT,\n",
    "        training_data= None,\n",
    "        parameters={\n",
    "            'epochs': 1, # example parameters\n",
    "            \"batch_size\" : 32\n",
    "        }\n",
    "    ),\n",
    "    timeout=14400\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the logs while training\n",
    "One way to measure our model performance during training is to check the logs. We can do so in the UI, or by using the relevant API endpoint. To format the the logs in a pretty way, we will use the `pprint` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "logs = core_instance.projects_log_list(\n",
    "    project_name = PROJECT_NAME,\n",
    "    data = {\n",
    "    \"date_range\": -86400, # Get results between current_datetime and 86400 seconds before\n",
    "    \"filters\": {\n",
    "        \"deployment_name\": \"training-base-deployment\",\n",
    "        \"deployment_request_id\": new_run.id, #\n",
    "        \"deployment_version\": EXPERIMENT_NAME,\n",
    " #       \"system\": False # Optional filter to enable/disable system-level logs, see docs: \"https://ubiops.com/docs/monitoring/logging/#system-logs\"\n",
    "    },\n",
    "    \"limit\": 100,\n",
    "    \"date\": current_datetime,\n",
    "})\n",
    "\n",
    "logs_body = {log.log for log in logs}\n",
    "pprint.pprint(logs_body, indent = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "So that's it! We have created a set-up where we can retrain ResNet on UbiOps using the PyTorch library. The training script,  model artifact and output metric are stored on UbiOps. This creates a proper basis for improving the accuracy of our final custom model. \n",
    "\n",
    "Let us close the connection to the UbiOps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_instance.client_close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
